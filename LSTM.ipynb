{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONPkcLDTomi2gM+C1KI2Gs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sboonpan/Project_Stock_LSTM/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmDn1hlT5hid",
        "outputId": "8490779c-ff89-49d6-f31e-0978230c814c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.7.1)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.11)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "Xa4PU_GO3cOB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol = 'PTT.BK'\n",
        "start  = '2000-01-01'\n",
        "end    = '2020-12-31'\n",
        "stock = yf.download(symbol, start, end) \n",
        "stock"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ctL5WOcD6FgI",
        "outputId": "9bef0b00-9971-4982-e584-c226cc73fd25"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb659e7c-6ff4-45b1-8906-fefaf2b67952\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2001-12-06</th>\n",
              "      <td>3.800</td>\n",
              "      <td>3.825</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.575</td>\n",
              "      <td>1.553146</td>\n",
              "      <td>1736808000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-07</th>\n",
              "      <td>3.625</td>\n",
              "      <td>3.625</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.550</td>\n",
              "      <td>1.542285</td>\n",
              "      <td>412533000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-10</th>\n",
              "      <td>3.550</td>\n",
              "      <td>3.550</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.550</td>\n",
              "      <td>1.542285</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-11</th>\n",
              "      <td>3.550</td>\n",
              "      <td>3.550</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.400</td>\n",
              "      <td>1.477117</td>\n",
              "      <td>409158000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-12</th>\n",
              "      <td>3.425</td>\n",
              "      <td>3.525</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.500</td>\n",
              "      <td>1.520562</td>\n",
              "      <td>307291000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-24</th>\n",
              "      <td>40.750</td>\n",
              "      <td>41.500</td>\n",
              "      <td>40.75</td>\n",
              "      <td>41.250</td>\n",
              "      <td>39.227222</td>\n",
              "      <td>45405500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-25</th>\n",
              "      <td>41.250</td>\n",
              "      <td>42.250</td>\n",
              "      <td>41.25</td>\n",
              "      <td>42.000</td>\n",
              "      <td>39.940445</td>\n",
              "      <td>32414000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-28</th>\n",
              "      <td>42.250</td>\n",
              "      <td>42.750</td>\n",
              "      <td>41.00</td>\n",
              "      <td>41.000</td>\n",
              "      <td>38.989479</td>\n",
              "      <td>60698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-29</th>\n",
              "      <td>41.250</td>\n",
              "      <td>42.500</td>\n",
              "      <td>41.00</td>\n",
              "      <td>42.500</td>\n",
              "      <td>40.415928</td>\n",
              "      <td>41046600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-30</th>\n",
              "      <td>43.250</td>\n",
              "      <td>43.250</td>\n",
              "      <td>42.25</td>\n",
              "      <td>42.500</td>\n",
              "      <td>40.415928</td>\n",
              "      <td>67293300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4729 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb659e7c-6ff4-45b1-8906-fefaf2b67952')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb659e7c-6ff4-45b1-8906-fefaf2b67952 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb659e7c-6ff4-45b1-8906-fefaf2b67952');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Open    High    Low   Close  Adj Close      Volume\n",
              "Date                                                            \n",
              "2001-12-06   3.800   3.825   3.55   3.575   1.553146  1736808000\n",
              "2001-12-07   3.625   3.625   3.55   3.550   1.542285   412533000\n",
              "2001-12-10   3.550   3.550   3.55   3.550   1.542285           0\n",
              "2001-12-11   3.550   3.550   3.40   3.400   1.477117   409158000\n",
              "2001-12-12   3.425   3.525   3.40   3.500   1.520562   307291000\n",
              "...            ...     ...    ...     ...        ...         ...\n",
              "2020-12-24  40.750  41.500  40.75  41.250  39.227222    45405500\n",
              "2020-12-25  41.250  42.250  41.25  42.000  39.940445    32414000\n",
              "2020-12-28  42.250  42.750  41.00  41.000  38.989479    60698100\n",
              "2020-12-29  41.250  42.500  41.00  42.500  40.415928    41046600\n",
              "2020-12-30  43.250  43.250  42.25  42.500  40.415928    67293300\n",
              "\n",
              "[4729 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = stock.copy()"
      ],
      "metadata": {
        "id": "7vWHAQue7K_G"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 0 to avoid dividing by 0 later on\n",
        "#df['Volume'].replace(to_replace=0, method='ffill', inplace=True) \n",
        "#df.sort_values('Date', inplace=True)\n",
        "df.drop(columns = 'Volume', inplace = True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "XXC7IaK23cDc",
        "outputId": "0b7c5747-8190-418c-f476-3331b66d2365"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a432cdd4-90c5-4bc4-88a7-c0d317ae0113\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2001-12-06</th>\n",
              "      <td>3.800</td>\n",
              "      <td>3.825</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.575</td>\n",
              "      <td>1.553146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-07</th>\n",
              "      <td>3.625</td>\n",
              "      <td>3.625</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.550</td>\n",
              "      <td>1.542285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-10</th>\n",
              "      <td>3.550</td>\n",
              "      <td>3.550</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.550</td>\n",
              "      <td>1.542285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-11</th>\n",
              "      <td>3.550</td>\n",
              "      <td>3.550</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.400</td>\n",
              "      <td>1.477117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-12</th>\n",
              "      <td>3.425</td>\n",
              "      <td>3.525</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.500</td>\n",
              "      <td>1.520562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-24</th>\n",
              "      <td>40.750</td>\n",
              "      <td>41.500</td>\n",
              "      <td>40.75</td>\n",
              "      <td>41.250</td>\n",
              "      <td>39.227222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-25</th>\n",
              "      <td>41.250</td>\n",
              "      <td>42.250</td>\n",
              "      <td>41.25</td>\n",
              "      <td>42.000</td>\n",
              "      <td>39.940445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-28</th>\n",
              "      <td>42.250</td>\n",
              "      <td>42.750</td>\n",
              "      <td>41.00</td>\n",
              "      <td>41.000</td>\n",
              "      <td>38.989479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-29</th>\n",
              "      <td>41.250</td>\n",
              "      <td>42.500</td>\n",
              "      <td>41.00</td>\n",
              "      <td>42.500</td>\n",
              "      <td>40.415928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-30</th>\n",
              "      <td>43.250</td>\n",
              "      <td>43.250</td>\n",
              "      <td>42.25</td>\n",
              "      <td>42.500</td>\n",
              "      <td>40.415928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4729 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a432cdd4-90c5-4bc4-88a7-c0d317ae0113')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a432cdd4-90c5-4bc4-88a7-c0d317ae0113 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a432cdd4-90c5-4bc4-88a7-c0d317ae0113');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Open    High    Low   Close  Adj Close\n",
              "Date                                                \n",
              "2001-12-06   3.800   3.825   3.55   3.575   1.553146\n",
              "2001-12-07   3.625   3.625   3.55   3.550   1.542285\n",
              "2001-12-10   3.550   3.550   3.55   3.550   1.542285\n",
              "2001-12-11   3.550   3.550   3.40   3.400   1.477117\n",
              "2001-12-12   3.425   3.525   3.40   3.500   1.520562\n",
              "...            ...     ...    ...     ...        ...\n",
              "2020-12-24  40.750  41.500  40.75  41.250  39.227222\n",
              "2020-12-25  41.250  42.250  41.25  42.000  39.940445\n",
              "2020-12-28  42.250  42.750  41.00  41.000  38.989479\n",
              "2020-12-29  41.250  42.500  41.00  42.500  40.415928\n",
              "2020-12-30  43.250  43.250  42.25  42.500  40.415928\n",
              "\n",
              "[4729 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMq0MKHB3aQa",
        "outputId": "d1b34600-347c-4463-b775-54434a78039f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4729 entries, 2001-12-06 to 2020-12-30\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       4729 non-null   float64\n",
            " 1   High       4729 non-null   float64\n",
            " 2   Low        4729 non-null   float64\n",
            " 3   Close      4729 non-null   float64\n",
            " 4   Adj Close  4729 non-null   float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 221.7 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Target'] = df['Adj Close'].shift(1)"
      ],
      "metadata": {
        "id": "TEi1ST9sinBV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df"
      ],
      "metadata": {
        "id": "k47Ei2lOim7-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.dropna(inplace = True)\n",
        "#df"
      ],
      "metadata": {
        "id": "1MW4ANWpi5bu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_split=round(len(df)*0.20)"
      ],
      "metadata": {
        "id": "2q69ZC7u6SN2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spVqtNBy6SK0",
        "outputId": "5dff7530-b8fd-4ba7-d117-d23ff7790aab"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "946"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training=df[:-test_split]\n",
        "df_for_testing=df[-test_split:]"
      ],
      "metadata": {
        "id": "8MglTzTL6SH9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_for_training.shape)\n",
        "print(df_for_testing.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_eRNK0b6SFF",
        "outputId": "3a021a36-583b-4622-f532-4e15bb2058a0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3783, 5)\n",
            "(946, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "df_for_training_scaled = scaler.fit_transform(df_for_training)"
      ],
      "metadata": {
        "id": "XpX8EB_O6SCY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_testing_scaled=scaler.transform(df_for_testing)"
      ],
      "metadata": {
        "id": "_fPvOwNr6R_g"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvZkW5XC6R8M",
        "outputId": "a3e36be3-c674-4f27-beb0-394cd96e5e2a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02211302, 0.02250608, 0.0170778 , 0.01642336, 0.00604818],\n",
              "       [0.01781327, 0.0176399 , 0.0170778 , 0.01581508, 0.00571609],\n",
              "       [0.01597051, 0.01581508, 0.0170778 , 0.01581508, 0.00571609],\n",
              "       ...,\n",
              "       [0.93611797, 0.9318735 , 0.92409867, 0.8880779 , 0.93553009],\n",
              "       [0.90663392, 0.8978102 , 0.92156857, 0.892944  , 0.94048922],\n",
              "       [0.89680597, 0.8880779 , 0.90385824, 0.8686131 , 0.91569301]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_aYNVaS8r8j",
        "outputId": "f56dc07a-bc09-4062-c185-02c2ea2061c8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3783, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_testing_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z9GOEDY9qTd",
        "outputId": "d60d17f6-ec00-4a2e-a374-05097c762ca0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.87960693, 0.89537715, 0.90385824, 0.89537715, 0.94296898],\n",
              "       [0.90417696, 0.8978102 , 0.91650846, 0.8880779 , 0.93553009],\n",
              "       [0.89926293, 0.90024335, 0.92662868, 0.892944  , 0.94048922],\n",
              "       ...,\n",
              "       [0.9668305 , 0.96958637, 0.96457934, 0.9270073 , 1.15071942],\n",
              "       [0.94226048, 0.96350365, 0.96457934, 0.96350365, 1.1943352 ],\n",
              "       [0.99140053, 0.98175182, 0.9962049 , 0.96350365, 1.1943352 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_testing_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSCf0U6U8r5L",
        "outputId": "0915ca74-3e90-486c-c1a3-870c0aa2f7c4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(946, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createXY(dataset,n_past):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(n_past, len(dataset)):\n",
        "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
        "            dataY.append(dataset[i,-1])\n",
        "    return np.array(dataX),np.array(dataY) "
      ],
      "metadata": {
        "id": "Z7Ttuk1H8r18"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX,trainY=createXY(df_for_training_scaled,30)"
      ],
      "metadata": {
        "id": "SdFUZj-w8ryt"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3ui2dgn-D73",
        "outputId": "38be327a-2f1e-4036-fa03-6715ec9da073"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3753, 30, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testX,testY=createXY(df_for_testing_scaled,30)"
      ],
      "metadata": {
        "id": "VxPq5bRN-D5B"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DZWH3f8-D2F",
        "outputId": "dad147e9-8b68-4ad2-e68d-45c19333122a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02211302, 0.02250608, 0.0170778 , 0.01642336, 0.00604818],\n",
              "       [0.01781327, 0.0176399 , 0.0170778 , 0.01581508, 0.00571609],\n",
              "       [0.01597051, 0.01581508, 0.0170778 , 0.01581508, 0.00571609],\n",
              "       [0.01597051, 0.01581508, 0.01328273, 0.01216545, 0.0037235 ],\n",
              "       [0.01289926, 0.01520681, 0.01328273, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01520681, 0.01581278, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01520681, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01412776, 0.01399026, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01399026, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01399026, 0.01391524, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01399026, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01338199, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01338199, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01399026, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01351351, 0.01399026, 0.01454776, 0.01277372, 0.00405561],\n",
              "       [0.01351351, 0.01399026, 0.01391524, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01277372, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01535627, 0.01520681, 0.01581278, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01520681, 0.01518026, 0.01399026, 0.00471978],\n",
              "       [0.01412776, 0.01520681, 0.01518026, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01581508, 0.01518026, 0.01399026, 0.00471978],\n",
              "       [0.01412776, 0.01459854, 0.01518026, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01459854, 0.01518026, 0.01459854, 0.00505189],\n",
              "       [0.01412776, 0.01459854, 0.01518026, 0.01399026, 0.00471978],\n",
              "       [0.01412776, 0.01399026, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01459854, 0.01454776, 0.01459854, 0.00505189]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainY[0]"
      ],
      "metadata": {
        "id": "ADeMd5NJkbnX",
        "outputId": "8cd705d4-e0a7-40c8-dfcd-c9b49a68625d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004719783294818619"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"trainX Shape-- \",trainX.shape)\n",
        "print(\"trainY Shape-- \",trainY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2UNhZ03-Dy2",
        "outputId": "b1b83c8d-87e0-4642-8f9c-e301f2d87813"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX Shape--  (3753, 30, 5)\n",
            "trainY Shape--  (3753,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"testX Shape-- \",testX.shape)\n",
        "print(\"testY Shape-- \",testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qUz84uv-Dvk",
        "outputId": "1b3a25e1-4c60-4c6b-8b63-d269494cc848"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testX Shape--  (916, 30, 5)\n",
            "testY Shape--  (916,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"trainX[0]-- \\n\",trainX[0])\n",
        "print(\"\\ntrainY[0]-- \",trainY[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcVoPDqp-DsV",
        "outputId": "0c49f740-3494-49dc-c73f-234e55922333"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX[0]-- \n",
            " [[0.02211302 0.02250608 0.0170778  0.01642336 0.00604818]\n",
            " [0.01781327 0.0176399  0.0170778  0.01581508 0.00571609]\n",
            " [0.01597051 0.01581508 0.0170778  0.01581508 0.00571609]\n",
            " [0.01597051 0.01581508 0.01328273 0.01216545 0.0037235 ]\n",
            " [0.01289926 0.01520681 0.01328273 0.01459854 0.00505189]\n",
            " [0.01474201 0.01520681 0.01581278 0.01459854 0.00505189]\n",
            " [0.01474201 0.01520681 0.01454776 0.01338199 0.00438769]\n",
            " [0.01412776 0.01399026 0.01454776 0.01338199 0.00438769]\n",
            " [0.01351351 0.01338199 0.01454776 0.01338199 0.00438769]\n",
            " [0.01351351 0.01399026 0.01391524 0.01277372 0.00405561]\n",
            " [0.01289926 0.01399026 0.01391524 0.01338199 0.00438769]\n",
            " [0.01351351 0.01399026 0.01391524 0.01277372 0.00405561]\n",
            " [0.01289926 0.01338199 0.01391524 0.01277372 0.00405561]\n",
            " [0.01289926 0.01338199 0.01391524 0.01277372 0.00405561]\n",
            " [0.01289926 0.01399026 0.01391524 0.01277372 0.00405561]\n",
            " [0.01351351 0.01399026 0.01454776 0.01277372 0.00405561]\n",
            " [0.01351351 0.01399026 0.01391524 0.01338199 0.00438769]\n",
            " [0.01351351 0.01338199 0.01454776 0.01338199 0.00438769]\n",
            " [0.01351351 0.01338199 0.01454776 0.01338199 0.00438769]\n",
            " [0.01351351 0.01338199 0.01391524 0.01277372 0.00405561]\n",
            " [0.01289926 0.01277372 0.01391524 0.01277372 0.00405561]\n",
            " [0.01535627 0.01520681 0.01581278 0.01459854 0.00505189]\n",
            " [0.01474201 0.01520681 0.01518026 0.01399026 0.00471978]\n",
            " [0.01412776 0.01520681 0.01518026 0.01459854 0.00505189]\n",
            " [0.01474201 0.01581508 0.01518026 0.01399026 0.00471978]\n",
            " [0.01412776 0.01459854 0.01518026 0.01459854 0.00505189]\n",
            " [0.01474201 0.01459854 0.01518026 0.01459854 0.00505189]\n",
            " [0.01412776 0.01459854 0.01518026 0.01399026 0.00471978]\n",
            " [0.01412776 0.01399026 0.01454776 0.01338199 0.00438769]\n",
            " [0.01351351 0.01459854 0.01454776 0.01459854 0.00505189]]\n",
            "\n",
            "trainY[0]--  0.004719783294818619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainY[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwuoqbHp-xI3",
        "outputId": "ffccd874-1568-46ff-b9fd-0125d8b88ef5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004719783294818619"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFe5X-0v-w-n",
        "outputId": "2cd97c59-c3e5-44e8-ffc2-3f5bcdffb667"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3753,)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX[1]"
      ],
      "metadata": {
        "id": "77XH-dFMrwsP",
        "outputId": "2c707d4e-646b-44af-eec8-1b0e7e1f385f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01781327, 0.0176399 , 0.0170778 , 0.01581508, 0.00571609],\n",
              "       [0.01597051, 0.01581508, 0.0170778 , 0.01581508, 0.00571609],\n",
              "       [0.01597051, 0.01581508, 0.01328273, 0.01216545, 0.0037235 ],\n",
              "       [0.01289926, 0.01520681, 0.01328273, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01520681, 0.01581278, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01520681, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01412776, 0.01399026, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01399026, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01399026, 0.01391524, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01399026, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01338199, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01338199, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01399026, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01351351, 0.01399026, 0.01454776, 0.01277372, 0.00405561],\n",
              "       [0.01351351, 0.01399026, 0.01391524, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01338199, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01289926, 0.01277372, 0.01391524, 0.01277372, 0.00405561],\n",
              "       [0.01535627, 0.01520681, 0.01581278, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01520681, 0.01518026, 0.01399026, 0.00471978],\n",
              "       [0.01412776, 0.01520681, 0.01518026, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01581508, 0.01518026, 0.01399026, 0.00471978],\n",
              "       [0.01412776, 0.01459854, 0.01518026, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01459854, 0.01518026, 0.01459854, 0.00505189],\n",
              "       [0.01412776, 0.01459854, 0.01518026, 0.01399026, 0.00471978],\n",
              "       [0.01412776, 0.01399026, 0.01454776, 0.01338199, 0.00438769],\n",
              "       [0.01351351, 0.01459854, 0.01454776, 0.01459854, 0.00505189],\n",
              "       [0.01474201, 0.01459854, 0.01454776, 0.01399026, 0.00471978]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "HQoPMdYr-w15"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(optimizer):\n",
        "    grid_model = Sequential()\n",
        "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(30,5)))\n",
        "    grid_model.add(LSTM(50))\n",
        "    grid_model.add(Dropout(0.2))\n",
        "    grid_model.add(Dense(1))\n",
        "\n",
        "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
        "    return grid_model\n",
        "\n",
        "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
        "parameters = {'batch_size' : [16,32,64,128],\n",
        "              'epochs' : [5,10,15,20],\n",
        "              'optimizer' : ['adam','Adadelta'] }\n",
        "\n",
        "grid_search  = GridSearchCV(estimator = grid_model,\n",
        "                            param_grid = parameters,\n",
        "                            cv = 4)"
      ],
      "metadata": {
        "id": "2ND1ToAj-5uf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = grid_search.fit(trainX,trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA50mYje-5mp",
        "outputId": "12f37e7a-9279-4010-f86a-3df59f10a108"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "176/176 [==============================] - 11s 20ms/step - loss: 0.0138 - val_loss: 0.0068\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 0.0036 - val_loss: 0.0050\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 0.0028 - val_loss: 0.0062\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 2s 14ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 2s 14ms/step - loss: 0.0024 - val_loss: 0.0104\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 1.7658e-04\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 7s 11ms/step - loss: 0.0107 - val_loss: 0.0068\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0056\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0063\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0061\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0051\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 4.5582e-04\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.0063 - val_loss: 0.0095\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0039\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0105\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0043\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 3.1918e-04\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.0065 - val_loss: 0.0221\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0120\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0116\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0105\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0135\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.3890 - val_loss: 1.4018\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3491 - val_loss: 1.2877\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3063 - val_loss: 1.1693\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2654 - val_loss: 1.0467\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2226 - val_loss: 0.9209\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0129\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 4s 12ms/step - loss: 0.0809 - val_loss: 0.5091\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0676 - val_loss: 0.4523\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0528 - val_loss: 0.3977\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0412 - val_loss: 0.3464\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0321 - val_loss: 0.2992\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.0036\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.1841 - val_loss: 1.1371\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1573 - val_loss: 1.0241\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1326 - val_loss: 0.9160\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1101 - val_loss: 0.8135\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0872 - val_loss: 0.7185\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.1037\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 5s 13ms/step - loss: 0.1806 - val_loss: 1.2410\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1509 - val_loss: 1.1154\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1279 - val_loss: 0.9914\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1032 - val_loss: 0.8712\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 2s 13ms/step - loss: 0.0825 - val_loss: 0.7578\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.2305\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.0123 - val_loss: 0.0074\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0051\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0051\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0107\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 6.9217e-05\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.0082 - val_loss: 0.0072\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0032\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0142\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0104\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0114\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0050\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0111\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 3.4158e-04\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.0142 - val_loss: 0.0028\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0026\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0056\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 4.8502e-04\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.0076 - val_loss: 0.0182\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0025\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0307\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0028\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0104\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0076\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7864e-04 - val_loss: 0.0081\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 5.9405e-04\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 5s 12ms/step - loss: 0.2576 - val_loss: 1.1189\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.2236 - val_loss: 1.0134\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1897 - val_loss: 0.9056\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1551 - val_loss: 0.7976\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1237 - val_loss: 0.6918\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0943 - val_loss: 0.5913\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0710 - val_loss: 0.4991\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0493 - val_loss: 0.4187\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0373 - val_loss: 0.3500\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0269 - val_loss: 0.2955\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0044\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 4s 12ms/step - loss: 0.0890 - val_loss: 0.5044\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0680 - val_loss: 0.4233\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0518 - val_loss: 0.3505\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0365 - val_loss: 0.2876\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0263 - val_loss: 0.2344\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.1921\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.1588\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.1351\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.1192\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0091 - val_loss: 0.1087\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0066\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.3282 - val_loss: 1.8019\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.2923 - val_loss: 1.6607\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2577 - val_loss: 1.5216\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2263 - val_loss: 1.3833\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1948 - val_loss: 1.2465\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1643 - val_loss: 1.1132\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1356 - val_loss: 0.9840\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1112 - val_loss: 0.8592\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0884 - val_loss: 0.7443\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0684 - val_loss: 0.6386\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.0732\n",
            "Epoch 1/10\n",
            "176/176 [==============================] - 5s 13ms/step - loss: 0.1027 - val_loss: 0.8395\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0828 - val_loss: 0.7427\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0671 - val_loss: 0.6502\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0513 - val_loss: 0.5660\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.4915\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0295 - val_loss: 0.4245\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0214 - val_loss: 0.3681\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.3222\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.2857\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.2587\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0347\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.0131 - val_loss: 0.0096\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0032 - val_loss: 0.0107\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0024\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0057\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0132\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0046\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0040\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 4.0704e-04\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.0080 - val_loss: 0.0065\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0034\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0122\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0109\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0070\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0066\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0077\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 3.1004e-04\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.0070 - val_loss: 0.0045\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0037\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0082\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0034\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0050\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0014\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0015\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 2.6147e-04\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 5s 12ms/step - loss: 0.0060 - val_loss: 0.0148\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0194\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0120\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0077\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0116\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0083\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9155e-04 - val_loss: 0.0073\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0051\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0075\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 8.6487e-04 - val_loss: 0.0016\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7943e-04 - val_loss: 0.0080\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5243e-04 - val_loss: 0.0069\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8262e-04 - val_loss: 0.0015\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 9.9739e-04\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 5s 12ms/step - loss: 0.2129 - val_loss: 0.9934\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1740 - val_loss: 0.8694\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1399 - val_loss: 0.7476\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1052 - val_loss: 0.6342\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0774 - val_loss: 0.5307\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0540 - val_loss: 0.4407\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.3643\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.3041\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.2584\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.2273\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.2084\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.1954\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.1901\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.1849\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.1821\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0082\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.2051 - val_loss: 1.0313\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1734 - val_loss: 0.9226\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1456 - val_loss: 0.8177\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1184 - val_loss: 0.7175\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0939 - val_loss: 0.6235\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0719 - val_loss: 0.5372\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0544 - val_loss: 0.4594\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0404 - val_loss: 0.3917\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0298 - val_loss: 0.3349\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0228 - val_loss: 0.2887\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.2537\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.2284\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.2084\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.1965\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0122 - val_loss: 0.1888\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0105\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.2381 - val_loss: 1.3401\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.2028 - val_loss: 1.1978\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1697 - val_loss: 1.0630\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1416 - val_loss: 0.9363\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1158 - val_loss: 0.8164\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0928 - val_loss: 0.7044\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0710 - val_loss: 0.6018\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0545 - val_loss: 0.5100\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0415 - val_loss: 0.4301\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0305 - val_loss: 0.3634\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0224 - val_loss: 0.3109\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.2702\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.2397\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.2165\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.2014\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.0031\n",
            "Epoch 1/15\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.1902 - val_loss: 1.3161\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1573 - val_loss: 1.1675\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1277 - val_loss: 1.0238\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1010 - val_loss: 0.8884\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0771 - val_loss: 0.7631\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0573 - val_loss: 0.6512\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0408 - val_loss: 0.5538\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0293 - val_loss: 0.4709\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.4031\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.3504\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.3124\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.2858\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0110 - val_loss: 0.2668\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.2531\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.2426\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.0272\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.0098 - val_loss: 0.0053\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0025\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0032\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0094\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0040\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0044\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0036\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8409e-04 - val_loss: 0.0019\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9808e-04 - val_loss: 0.0014\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 1.1904e-04\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 5s 13ms/step - loss: 0.0103 - val_loss: 0.0035\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0036\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0051\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0076\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0085\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0045\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0028\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0046\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0049\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0038\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 9.5228e-04 - val_loss: 0.0024\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 5.2451e-04\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.0141 - val_loss: 0.0035\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0058\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0067\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0034\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0052\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0047\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 9.0396e-04 - val_loss: 0.0015\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 9.2043e-04 - val_loss: 0.0011\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8980e-04 - val_loss: 0.0029\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 3.3540e-04\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 5s 11ms/step - loss: 0.0057 - val_loss: 0.0501\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0111\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0098\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0071\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0064\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0146\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0140\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0119\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0229\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9823e-04 - val_loss: 0.0217\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 9.4404e-04 - val_loss: 0.0126\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 8.0224e-04 - val_loss: 0.0079\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 7.8708e-04 - val_loss: 0.0099\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 7.8911e-04 - val_loss: 0.0018\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 7.9705e-04 - val_loss: 0.0095\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 6.5743e-04 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 7.4438e-04 - val_loss: 0.0076\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.4608e-04 - val_loss: 0.0049\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 6.4893e-04 - val_loss: 0.0056\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1497e-04 - val_loss: 0.0070\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 5.4103e-04\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 4s 11ms/step - loss: 0.1896 - val_loss: 0.8628\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1590 - val_loss: 0.7693\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1308 - val_loss: 0.6757\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1035 - val_loss: 0.5854\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0794 - val_loss: 0.5009\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0580 - val_loss: 0.4245\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0428 - val_loss: 0.3576\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0309 - val_loss: 0.3009\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0225 - val_loss: 0.2556\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.2214\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.1978\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.1810\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.1701\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.1641\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.1590\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.1569\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.1536\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.1509\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0120 - val_loss: 0.1484\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.1472\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.0064\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 5s 12ms/step - loss: 0.2087 - val_loss: 1.0054\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1854 - val_loss: 0.9182\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1589 - val_loss: 0.8298\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1376 - val_loss: 0.7403\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1130 - val_loss: 0.6524\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0919 - val_loss: 0.5677\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0711 - val_loss: 0.4892\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0544 - val_loss: 0.4177\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0413 - val_loss: 0.3537\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0305 - val_loss: 0.2986\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0231 - val_loss: 0.2525\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.2161\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.1895\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.1699\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.0111 - val_loss: 0.1583\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.1489\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.1428\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.1398\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.1358\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.1340\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0098\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 5s 13ms/step - loss: 0.3564 - val_loss: 1.7241\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.3205 - val_loss: 1.5820\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.2813 - val_loss: 1.4444\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.2481 - val_loss: 1.3114\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.2142 - val_loss: 1.1869\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1845 - val_loss: 1.0671\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1578 - val_loss: 0.9545\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1303 - val_loss: 0.8498\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1066 - val_loss: 0.7533\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0875 - val_loss: 0.6638\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0724 - val_loss: 0.5820\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0573 - val_loss: 0.5087\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0457 - val_loss: 0.4442\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0365 - val_loss: 0.3869\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.3385\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0238 - val_loss: 0.2983\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0203 - val_loss: 0.2664\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.2405\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.2205\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.2050\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0037\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 5s 12ms/step - loss: 0.2210 - val_loss: 1.5196\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1945 - val_loss: 1.3827\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1632 - val_loss: 1.2469\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1371 - val_loss: 1.1107\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1105 - val_loss: 0.9786\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0851 - val_loss: 0.8538\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0668 - val_loss: 0.7364\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0493 - val_loss: 0.6312\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0351 - val_loss: 0.5402\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0249 - val_loss: 0.4636\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.4008\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.3538\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.3206\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.2972\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.2793\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.2699\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.2632\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.2574\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.2524\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.2474\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.0278\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.0170 - val_loss: 0.0469\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0158\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0080\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 7.0431e-05\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.0142 - val_loss: 0.0359\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0080\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0040\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0042\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.6912e-04\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0075 - val_loss: 0.0039\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0060\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 3.5133e-04\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 19ms/step - loss: 0.0055 - val_loss: 0.0303\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0203\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0138\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0073\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0081\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.2700 - val_loss: 1.0815\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2457 - val_loss: 1.0191\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2224 - val_loss: 0.9568\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2015 - val_loss: 0.8949\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1816 - val_loss: 0.8340\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0105\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.2139 - val_loss: 1.0561\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1993 - val_loss: 1.0054\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1850 - val_loss: 0.9537\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1692 - val_loss: 0.9020\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1565 - val_loss: 0.8497\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0682\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.3299 - val_loss: 1.6466\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3020 - val_loss: 1.5401\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2751 - val_loss: 1.4346\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2465 - val_loss: 1.3309\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2207 - val_loss: 1.2296\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2998\n",
            "Epoch 1/5\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.1965 - val_loss: 1.3569\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1813 - val_loss: 1.2939\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1685 - val_loss: 1.2312\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1561 - val_loss: 1.1682\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1428 - val_loss: 1.1061\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3765\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0188 - val_loss: 0.0541\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0123\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0023\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0098\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0045\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0034\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.9014e-04\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0149 - val_loss: 0.0307\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0149\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0167\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0052\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0066\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0136\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0107\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0036\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0074\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.3953e-04\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.0135 - val_loss: 0.0369\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0036\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0036\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0038\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0109\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 4.3839e-04\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0089 - val_loss: 0.0397\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0111\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0078\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0087\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0067\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0087\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0038\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.9000e-04\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.5097 - val_loss: 1.8520\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4798 - val_loss: 1.7690\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4496 - val_loss: 1.6847\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4160 - val_loss: 1.5998\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3880 - val_loss: 1.5138\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3563 - val_loss: 1.4275\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3260 - val_loss: 1.3411\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2934 - val_loss: 1.2549\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2680 - val_loss: 1.1682\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2372 - val_loss: 1.0825\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0125\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.1436 - val_loss: 0.7076\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1302 - val_loss: 0.6555\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1151 - val_loss: 0.6038\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1020 - val_loss: 0.5530\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0869 - val_loss: 0.5038\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0749 - val_loss: 0.4570\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0649 - val_loss: 0.4122\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0563 - val_loss: 0.3698\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0457 - val_loss: 0.3309\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0375 - val_loss: 0.2955\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.3248 - val_loss: 1.6769\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.3148 - val_loss: 1.6203\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3003 - val_loss: 1.5621\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2835 - val_loss: 1.5027\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.2705 - val_loss: 1.4424\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2565 - val_loss: 1.3807\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.2406 - val_loss: 1.3180\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.2249 - val_loss: 1.2546\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2100 - val_loss: 1.1904\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1937 - val_loss: 1.1255\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.2692\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.2062 - val_loss: 1.5498\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1914 - val_loss: 1.4819\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1788 - val_loss: 1.4132\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1651 - val_loss: 1.3448\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1497 - val_loss: 1.2768\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1375 - val_loss: 1.2094\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1259 - val_loss: 1.1427\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1142 - val_loss: 1.0770\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1024 - val_loss: 1.0130\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0898 - val_loss: 0.9508\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2807\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 18ms/step - loss: 0.0139 - val_loss: 0.0028\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0084\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0034\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0040\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.9414e-04\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0175 - val_loss: 0.0244\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0058\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0192\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0111\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0073\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0078\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0061\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0031\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0038\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0058\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0080\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.1962e-04\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0164 - val_loss: 0.0156\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0087\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0031\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0210\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0052\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0110\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0026\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0060\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0022\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0100\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0051\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.8228e-04\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0081 - val_loss: 0.0783\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0160\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0093\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0113\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0076\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0079\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0049\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0045\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0083\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0047\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 8.7306e-04 - val_loss: 0.0057\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 8.1157e-04\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.3734 - val_loss: 1.5202\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3480 - val_loss: 1.4536\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3265 - val_loss: 1.3851\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3019 - val_loss: 1.3163\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2791 - val_loss: 1.2470\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2569 - val_loss: 1.1777\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2324 - val_loss: 1.1090\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2115 - val_loss: 1.0413\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1920 - val_loss: 0.9745\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1696 - val_loss: 0.9098\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1514 - val_loss: 0.8463\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1342 - val_loss: 0.7846\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1190 - val_loss: 0.7252\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1005 - val_loss: 0.6689\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0883 - val_loss: 0.6150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 18ms/step - loss: 0.4260 - val_loss: 1.7780\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4064 - val_loss: 1.7148\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3841 - val_loss: 1.6499\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3628 - val_loss: 1.5837\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3454 - val_loss: 1.5162\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3228 - val_loss: 1.4478\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3059 - val_loss: 1.3785\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2826 - val_loss: 1.3091\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2612 - val_loss: 1.2390\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2422 - val_loss: 1.1685\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2204 - val_loss: 1.0982\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2019 - val_loss: 1.0275\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1812 - val_loss: 0.9568\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1639 - val_loss: 0.8865\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1432 - val_loss: 0.8172\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0548\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.2152 - val_loss: 1.2916\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2035 - val_loss: 1.2440\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1906 - val_loss: 1.1955\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1785 - val_loss: 1.1460\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1670 - val_loss: 1.0955\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1553 - val_loss: 1.0446\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1430 - val_loss: 0.9936\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1352 - val_loss: 0.9420\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1217 - val_loss: 0.8911\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1105 - val_loss: 0.8408\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1006 - val_loss: 0.7910\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0915 - val_loss: 0.7422\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0814 - val_loss: 0.6945\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0731 - val_loss: 0.6485\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0636 - val_loss: 0.6046\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0739\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.1047 - val_loss: 0.8532\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0945 - val_loss: 0.8079\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0870 - val_loss: 0.7624\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0773 - val_loss: 0.7180\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0698 - val_loss: 0.6742\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0613 - val_loss: 0.6317\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0531 - val_loss: 0.5905\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0477 - val_loss: 0.5509\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0400 - val_loss: 0.5132\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0333 - val_loss: 0.4778\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.4443\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0255 - val_loss: 0.4128\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0210 - val_loss: 0.3845\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.3580\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.3348\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.0581\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.0197 - val_loss: 0.0315\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0037\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0024\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0084\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0014\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0031\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0038\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0042\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.6849e-04\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.0139 - val_loss: 0.0561\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0101\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0239\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0087\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0120\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0035\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0147\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0101\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0114\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0034\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0117\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0097\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0060\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0027\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0045\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.3988e-04\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 18ms/step - loss: 0.0118 - val_loss: 0.0059\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0032\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0049\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0052\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0035\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 3.6758e-04\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 15ms/step - loss: 0.0058 - val_loss: 0.0332\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0035\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0218\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0031\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0159\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0177\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0068\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0077\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0047\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 9.7890e-04 - val_loss: 0.0059\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0064\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 9.1006e-04 - val_loss: 0.0058\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 8.8150e-04 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 8.9651e-04 - val_loss: 0.0083\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0076\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 8.6266e-04 - val_loss: 0.0029\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 7.5198e-04 - val_loss: 0.0056\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 7.6429e-04 - val_loss: 0.0028\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 5.6672e-04\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.4776 - val_loss: 1.6188\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4505 - val_loss: 1.5397\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4219 - val_loss: 1.4598\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3898 - val_loss: 1.3798\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3563 - val_loss: 1.3001\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3269 - val_loss: 1.2204\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2973 - val_loss: 1.1412\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2685 - val_loss: 1.0628\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2450 - val_loss: 0.9846\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2155 - val_loss: 0.9089\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1946 - val_loss: 0.8340\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1707 - val_loss: 0.7616\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1451 - val_loss: 0.6926\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1250 - val_loss: 0.6267\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1086 - val_loss: 0.5632\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0896 - val_loss: 0.5046\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0745 - val_loss: 0.4502\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0608 - val_loss: 0.4004\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0500 - val_loss: 0.3562\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0409 - val_loss: 0.3168\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.5672 - val_loss: 2.3160\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5420 - val_loss: 2.2319\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5173 - val_loss: 2.1470\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4902 - val_loss: 2.0614\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4630 - val_loss: 1.9755\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4340 - val_loss: 1.8905\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4121 - val_loss: 1.8047\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3902 - val_loss: 1.7178\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3634 - val_loss: 1.6308\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3395 - val_loss: 1.5441\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3149 - val_loss: 1.4572\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2898 - val_loss: 1.3698\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2637 - val_loss: 1.2823\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2420 - val_loss: 1.1948\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2154 - val_loss: 1.1079\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1942 - val_loss: 1.0217\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1717 - val_loss: 0.9368\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1504 - val_loss: 0.8539\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1301 - val_loss: 0.7736\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1086 - val_loss: 0.6971\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0340\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 16ms/step - loss: 0.1357 - val_loss: 1.0062\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1252 - val_loss: 0.9615\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1173 - val_loss: 0.9158\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1056 - val_loss: 0.8702\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0983 - val_loss: 0.8246\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0891 - val_loss: 0.7798\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0823 - val_loss: 0.7354\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0738 - val_loss: 0.6925\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0658 - val_loss: 0.6510\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0580 - val_loss: 0.6109\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0524 - val_loss: 0.5722\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0461 - val_loss: 0.5355\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0411 - val_loss: 0.5005\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0368 - val_loss: 0.4676\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0317 - val_loss: 0.4376\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0284 - val_loss: 0.4094\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0260 - val_loss: 0.3833\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0234 - val_loss: 0.3596\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.3377\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0198 - val_loss: 0.3185\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0095\n",
            "Epoch 1/20\n",
            "88/88 [==============================] - 4s 19ms/step - loss: 0.1822 - val_loss: 1.4335\n",
            "Epoch 2/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1699 - val_loss: 1.3702\n",
            "Epoch 3/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1578 - val_loss: 1.3060\n",
            "Epoch 4/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1436 - val_loss: 1.2410\n",
            "Epoch 5/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1308 - val_loss: 1.1762\n",
            "Epoch 6/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1174 - val_loss: 1.1119\n",
            "Epoch 7/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1080 - val_loss: 1.0473\n",
            "Epoch 8/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0921 - val_loss: 0.9851\n",
            "Epoch 9/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0832 - val_loss: 0.9238\n",
            "Epoch 10/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0725 - val_loss: 0.8647\n",
            "Epoch 11/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0649 - val_loss: 0.8075\n",
            "Epoch 12/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0550 - val_loss: 0.7528\n",
            "Epoch 13/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0472 - val_loss: 0.7008\n",
            "Epoch 14/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0402 - val_loss: 0.6521\n",
            "Epoch 15/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0341 - val_loss: 0.6066\n",
            "Epoch 16/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0293 - val_loss: 0.5640\n",
            "Epoch 17/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0242 - val_loss: 0.5256\n",
            "Epoch 18/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0207 - val_loss: 0.4911\n",
            "Epoch 19/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.4607\n",
            "Epoch 20/20\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.4331\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0708\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0446 - val_loss: 0.1494\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0537\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0033\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0111\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.0405e-05\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0376 - val_loss: 0.1129\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0211\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0067\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.9573e-04\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0186 - val_loss: 0.0524\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0047\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0046\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2350e-04\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0192 - val_loss: 0.1298\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0458\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0231\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0129\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0089\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 4s 32ms/step - loss: 0.4397 - val_loss: 1.6424\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4283 - val_loss: 1.6070\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4153 - val_loss: 1.5707\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4025 - val_loss: 1.5340\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.3912 - val_loss: 1.4966\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0339\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 3s 25ms/step - loss: 0.3436 - val_loss: 1.5625\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.3355 - val_loss: 1.5347\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.3268 - val_loss: 1.5063\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3200 - val_loss: 1.4774\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3117 - val_loss: 1.4482\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1785\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.3879 - val_loss: 1.7388\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3787 - val_loss: 1.7017\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.3668 - val_loss: 1.6641\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3542 - val_loss: 1.6260\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3445 - val_loss: 1.5872\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4978\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.1123 - val_loss: 1.0388\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1073 - val_loss: 1.0096\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1019 - val_loss: 0.9806\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0971 - val_loss: 0.9516\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0915 - val_loss: 0.9225\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2999\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0260 - val_loss: 0.1061\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0098\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0026\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0052\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.9776e-04\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0181 - val_loss: 0.0561\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0238\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0093\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0036\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0057\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0095\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0075\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.2497e-04\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0088 - val_loss: 0.0037\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0052\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5034e-04\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0152 - val_loss: 0.1800\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0833\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0186\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0058\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0036\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0133\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0056\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.1734e-04\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.2549 - val_loss: 1.0754\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2480 - val_loss: 1.0523\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.2394 - val_loss: 1.0289\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.2327 - val_loss: 1.0052\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2225 - val_loss: 0.9814\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.2160 - val_loss: 0.9573\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2067 - val_loss: 0.9331\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1993 - val_loss: 0.9088\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1908 - val_loss: 0.8844\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1845 - val_loss: 0.8598\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0109\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0881 - val_loss: 0.6179\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0810 - val_loss: 0.5962\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0782 - val_loss: 0.5743\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0714 - val_loss: 0.5528\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0680 - val_loss: 0.5317\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.5109\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0584 - val_loss: 0.4906\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0544 - val_loss: 0.4706\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0497 - val_loss: 0.4513\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0458 - val_loss: 0.4326\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0061\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.3194 - val_loss: 1.6190\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3058 - val_loss: 1.5759\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2955 - val_loss: 1.5327\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2859 - val_loss: 1.4889\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2781 - val_loss: 1.4446\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2632 - val_loss: 1.4004\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2542 - val_loss: 1.3561\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2454 - val_loss: 1.3115\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2343 - val_loss: 1.2668\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2243 - val_loss: 1.2223\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3112\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0974 - val_loss: 0.8419\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0953 - val_loss: 0.8185\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0898 - val_loss: 0.7949\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0844 - val_loss: 0.7715\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0815 - val_loss: 0.7478\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0765 - val_loss: 0.7243\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0727 - val_loss: 0.7008\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.6774\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.6542\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.6313\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2012\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0341 - val_loss: 0.1670\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0336\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0027\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0039\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0054\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0069\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.1343e-05\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0122 - val_loss: 0.0540\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0082\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0041\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 3.7559e-04\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0307 - val_loss: 0.1037\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0091\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0062\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0033\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0082\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.6524e-04\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0188 - val_loss: 0.1352\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0456\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0156\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0070\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0084\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0077\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0130\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0043\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.5036e-04\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.2185 - val_loss: 0.8958\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2077 - val_loss: 0.8713\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2024 - val_loss: 0.8465\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1928 - val_loss: 0.8215\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1835 - val_loss: 0.7963\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1754 - val_loss: 0.7711\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1670 - val_loss: 0.7458\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1604 - val_loss: 0.7203\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1506 - val_loss: 0.6949\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1431 - val_loss: 0.6695\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1351 - val_loss: 0.6443\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1269 - val_loss: 0.6192\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1191 - val_loss: 0.5943\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1134 - val_loss: 0.5694\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1033 - val_loss: 0.5451\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0040\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 4s 26ms/step - loss: 0.3200 - val_loss: 1.3727\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3090 - val_loss: 1.3334\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2975 - val_loss: 1.2938\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2828 - val_loss: 1.2542\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2692 - val_loss: 1.2146\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.2587 - val_loss: 1.1748\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2461 - val_loss: 1.1350\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2348 - val_loss: 1.0952\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2228 - val_loss: 1.0557\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2112 - val_loss: 1.0162\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2008 - val_loss: 0.9768\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1896 - val_loss: 0.9376\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1803 - val_loss: 0.8987\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1650 - val_loss: 0.8604\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1564 - val_loss: 0.8225\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0746\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.1581 - val_loss: 1.0540\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1522 - val_loss: 1.0293\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.1455 - val_loss: 1.0044\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1420 - val_loss: 0.9792\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1345 - val_loss: 0.9540\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.1289 - val_loss: 0.9287\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1249 - val_loss: 0.9032\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1202 - val_loss: 0.8777\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1151 - val_loss: 0.8521\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1090 - val_loss: 0.8266\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1039 - val_loss: 0.8013\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0990 - val_loss: 0.7761\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0939 - val_loss: 0.7509\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0890 - val_loss: 0.7257\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0845 - val_loss: 0.7008\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1087\n",
            "Epoch 1/15\n",
            "44/44 [==============================] - 3s 25ms/step - loss: 0.1721 - val_loss: 1.2128\n",
            "Epoch 2/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1652 - val_loss: 1.1906\n",
            "Epoch 3/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1608 - val_loss: 1.1680\n",
            "Epoch 4/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1569 - val_loss: 1.1451\n",
            "Epoch 5/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1513 - val_loss: 1.1219\n",
            "Epoch 6/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1459 - val_loss: 1.0985\n",
            "Epoch 7/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1417 - val_loss: 1.0748\n",
            "Epoch 8/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.1339 - val_loss: 1.0512\n",
            "Epoch 9/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1309 - val_loss: 1.0272\n",
            "Epoch 10/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1254 - val_loss: 1.0032\n",
            "Epoch 11/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1217 - val_loss: 0.9792\n",
            "Epoch 12/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1163 - val_loss: 0.9552\n",
            "Epoch 13/15\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.1099 - val_loss: 0.9312\n",
            "Epoch 14/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1063 - val_loss: 0.9072\n",
            "Epoch 15/15\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1013 - val_loss: 0.8832\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2889\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 25ms/step - loss: 0.0250 - val_loss: 0.0792\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0102\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0041\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0067\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0030\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0039\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0032\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0153e-04\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 3s 24ms/step - loss: 0.0209 - val_loss: 0.0634\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0234\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0090\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0054\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0028\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2306e-04\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 27ms/step - loss: 0.0282 - val_loss: 0.0798\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0085\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0064\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0031\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0029\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0074\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0067\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0037\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0040\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0073\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.2864e-04\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0118 - val_loss: 0.1132\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0724\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0315\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0238\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0137\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0041\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0083\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0043\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0087\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0160\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0074\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0084\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0050\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0077\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0081\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0108\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0089\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0078\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0072\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 9.9324e-04 - val_loss: 0.0064\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.0791e-04\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 3s 23ms/step - loss: 0.4624 - val_loss: 1.7608\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4494 - val_loss: 1.7246\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.4369 - val_loss: 1.6878\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4256 - val_loss: 1.6505\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4128 - val_loss: 1.6130\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3939 - val_loss: 1.5754\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3830 - val_loss: 1.5373\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3721 - val_loss: 1.4991\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3593 - val_loss: 1.4604\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3421 - val_loss: 1.4220\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3286 - val_loss: 1.3835\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3167 - val_loss: 1.3449\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3043 - val_loss: 1.3063\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.2933 - val_loss: 1.2675\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2789 - val_loss: 1.2288\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2664 - val_loss: 1.1902\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2574 - val_loss: 1.1514\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2423 - val_loss: 1.1128\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2301 - val_loss: 1.0744\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2177 - val_loss: 1.0360\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0117\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 24ms/step - loss: 0.0968 - val_loss: 0.5987\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0910 - val_loss: 0.5734\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0836 - val_loss: 0.5487\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0784 - val_loss: 0.5242\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0726 - val_loss: 0.5003\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0694 - val_loss: 0.4766\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0616 - val_loss: 0.4539\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0574 - val_loss: 0.4314\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0531 - val_loss: 0.4097\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0498 - val_loss: 0.3886\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.3682\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.3486\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0369 - val_loss: 0.3297\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.3115\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.2944\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.2783\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.2630\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.2481\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.2346\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.2216\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 30ms/step - loss: 0.4354 - val_loss: 2.0022\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4253 - val_loss: 1.9625\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4162 - val_loss: 1.9221\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4102 - val_loss: 1.8808\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3927 - val_loss: 1.8395\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3815 - val_loss: 1.7978\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3704 - val_loss: 1.7557\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3597 - val_loss: 1.7133\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3494 - val_loss: 1.6706\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3372 - val_loss: 1.6276\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3227 - val_loss: 1.5845\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3139 - val_loss: 1.5413\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.3022 - val_loss: 1.4979\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2880 - val_loss: 1.4545\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2795 - val_loss: 1.4108\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2689 - val_loss: 1.3668\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2573 - val_loss: 1.3226\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2455 - val_loss: 1.2786\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 1.2347\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 1.1907\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3140\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 3s 25ms/step - loss: 0.2657 - val_loss: 1.6458\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2584 - val_loss: 1.6146\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2492 - val_loss: 1.5830\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2439 - val_loss: 1.5507\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.2349 - val_loss: 1.5180\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2272 - val_loss: 1.4850\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2192 - val_loss: 1.4516\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.2115 - val_loss: 1.4180\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.2024 - val_loss: 1.3842\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.1940 - val_loss: 1.3500\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1868 - val_loss: 1.3156\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1792 - val_loss: 1.2809\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1704 - val_loss: 1.2464\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1638 - val_loss: 1.2115\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.1570 - val_loss: 1.1765\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.1473 - val_loss: 1.1414\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1413 - val_loss: 1.1064\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1336 - val_loss: 1.0715\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.1256 - val_loss: 1.0367\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.1185 - val_loss: 1.0017\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3410\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 42ms/step - loss: 0.0476 - val_loss: 0.2003\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.1318\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0569\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0082\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0028\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5667e-04\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 42ms/step - loss: 0.0440 - val_loss: 0.1521\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.1050\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0651\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0404\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0290\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0030\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.0592 - val_loss: 0.2293\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0963\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0065\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0034\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6362e-04\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 54ms/step - loss: 0.0183 - val_loss: 0.1446\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.1121\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.1049\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0740\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0656\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0107\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.4780 - val_loss: 1.8671\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.4714 - val_loss: 1.8511\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.4655 - val_loss: 1.8350\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.4597 - val_loss: 1.8187\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.4558 - val_loss: 1.8022\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0384\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.2220 - val_loss: 1.1832\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2192 - val_loss: 1.1733\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2172 - val_loss: 1.1631\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2153 - val_loss: 1.1529\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.2120 - val_loss: 1.1424\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1060\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 40ms/step - loss: 0.3526 - val_loss: 1.7134\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3449 - val_loss: 1.6958\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3421 - val_loss: 1.6780\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3360 - val_loss: 1.6600\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3337 - val_loss: 1.6420\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4818\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.1519 - val_loss: 1.2487\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1496 - val_loss: 1.2393\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1474 - val_loss: 1.2298\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1462 - val_loss: 1.2201\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1434 - val_loss: 1.2103\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4216\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.0533 - val_loss: 0.2148\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.1438\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0796\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0217\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 0.0073\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0063\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0040\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0048\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8905e-04\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.0805 - val_loss: 0.2847\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.1375\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0734\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0301\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0140\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0051\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0034\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6299e-04\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.0283 - val_loss: 0.0451\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0167\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0032\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0035\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3901e-04\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.0256 - val_loss: 0.1597\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.1261\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0770\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0598\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0382\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0238\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0178\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0075\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0043\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 4s 42ms/step - loss: 0.3537 - val_loss: 1.4581\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3496 - val_loss: 1.4403\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3437 - val_loss: 1.4224\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3374 - val_loss: 1.4043\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3279 - val_loss: 1.3861\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3260 - val_loss: 1.3678\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3198 - val_loss: 1.3494\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3148 - val_loss: 1.3308\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3067 - val_loss: 1.3121\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3006 - val_loss: 1.2935\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0232\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 4s 42ms/step - loss: 0.3417 - val_loss: 1.5291\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3391 - val_loss: 1.5113\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3296 - val_loss: 1.4935\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3278 - val_loss: 1.4753\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3201 - val_loss: 1.4572\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3156 - val_loss: 1.4390\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3074 - val_loss: 1.4208\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3054 - val_loss: 1.4024\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2986 - val_loss: 1.3839\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2938 - val_loss: 1.3654\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1742\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.1952 - val_loss: 1.1965\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1922 - val_loss: 1.1794\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1863 - val_loss: 1.1622\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1839 - val_loss: 1.1448\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1765 - val_loss: 1.1274\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.1769 - val_loss: 1.1098\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1733 - val_loss: 1.0921\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1687 - val_loss: 1.0744\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1622 - val_loss: 1.0568\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1575 - val_loss: 1.0392\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2194\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.2096 - val_loss: 1.4814\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2069 - val_loss: 1.4657\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2020 - val_loss: 1.4499\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1994 - val_loss: 1.4339\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1949 - val_loss: 1.4179\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1914 - val_loss: 1.4017\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1887 - val_loss: 1.3853\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1866 - val_loss: 1.3688\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1829 - val_loss: 1.3522\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1772 - val_loss: 1.3355\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4952\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 3s 40ms/step - loss: 0.0358 - val_loss: 0.0799\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0583\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0117\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0038\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0068\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 0.0030\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0050\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0044\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0034\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0048\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0032\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0031\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4305e-04\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.0327 - val_loss: 0.0870\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0509\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0206\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0122\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0060\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0036\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0056\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0033\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0043\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0029\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0033\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1307e-04\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 4s 54ms/step - loss: 0.0299 - val_loss: 0.0845\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0420\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0063\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0072\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0033\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0026\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0066\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0044\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5720e-04\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.0442 - val_loss: 0.2962\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.1521\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0895\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0591\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0328\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0269\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0202\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0107\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0074\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0036\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0026\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.5194e-04\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 4s 42ms/step - loss: 0.1548 - val_loss: 0.8432\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1490 - val_loss: 0.8283\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1448 - val_loss: 0.8134\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1413 - val_loss: 0.7984\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1389 - val_loss: 0.7833\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1353 - val_loss: 0.7683\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1292 - val_loss: 0.7534\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1253 - val_loss: 0.7385\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1212 - val_loss: 0.7237\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1174 - val_loss: 0.7089\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1131 - val_loss: 0.6943\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1102 - val_loss: 0.6796\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1058 - val_loss: 0.6651\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1024 - val_loss: 0.6506\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0980 - val_loss: 0.6363\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0020\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.3272 - val_loss: 1.3827\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3209 - val_loss: 1.3673\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3158 - val_loss: 1.3517\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3082 - val_loss: 1.3360\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3060 - val_loss: 1.3202\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3021 - val_loss: 1.3041\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2954 - val_loss: 1.2879\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2921 - val_loss: 1.2717\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2873 - val_loss: 1.2554\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2807 - val_loss: 1.2390\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2778 - val_loss: 1.2224\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2741 - val_loss: 1.2057\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2680 - val_loss: 1.1890\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2644 - val_loss: 1.1721\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2586 - val_loss: 1.1552\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1525\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 4s 42ms/step - loss: 0.2179 - val_loss: 1.1592\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2169 - val_loss: 1.1451\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2115 - val_loss: 1.1309\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2081 - val_loss: 1.1165\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2052 - val_loss: 1.1019\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1998 - val_loss: 1.0874\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1967 - val_loss: 1.0727\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1924 - val_loss: 1.0579\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1894 - val_loss: 1.0430\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1857 - val_loss: 1.0280\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1810 - val_loss: 1.0131\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1792 - val_loss: 0.9980\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1742 - val_loss: 0.9829\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1681 - val_loss: 0.9678\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1656 - val_loss: 0.9527\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2311\n",
            "Epoch 1/15\n",
            "22/22 [==============================] - 3s 54ms/step - loss: 0.3233 - val_loss: 2.1869\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3163 - val_loss: 2.1588\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3101 - val_loss: 2.1307\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3062 - val_loss: 2.1021\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2958 - val_loss: 2.0736\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2924 - val_loss: 2.0449\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2876 - val_loss: 2.0160\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2792 - val_loss: 1.9871\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2747 - val_loss: 1.9581\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2683 - val_loss: 1.9289\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2614 - val_loss: 1.8998\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2565 - val_loss: 1.8707\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2511 - val_loss: 1.8413\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2441 - val_loss: 1.8121\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2357 - val_loss: 1.7830\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6625\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 0.0315 - val_loss: 0.0818\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0597\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0227\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0041\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0054\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0029 - val_loss: 0.0072\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0051\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0036\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0039\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0033\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0037\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0037\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0032\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6119e-04\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.0312 - val_loss: 0.1026\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0691\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0400\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0263\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0152\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0075\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0055\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0041\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0057\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0079\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0106\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0064\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0128\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0076\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0072\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0120\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0073\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0064\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0096\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1186e-04\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 3s 40ms/step - loss: 0.0347 - val_loss: 0.1334\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0386\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0085\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0025\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0032\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0033\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0035\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0033\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3069e-04\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 4s 45ms/step - loss: 0.0417 - val_loss: 0.3353\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.1872\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.1232\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.1023\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0663\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0575\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0476\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0365\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0199\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0134\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0090\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0041\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0045\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0035\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0038\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9652e-04\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 3s 53ms/step - loss: 0.3676 - val_loss: 1.4794\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3605 - val_loss: 1.4634\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.3569 - val_loss: 1.4471\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3507 - val_loss: 1.4307\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3429 - val_loss: 1.4142\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3373 - val_loss: 1.3975\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3358 - val_loss: 1.3805\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3301 - val_loss: 1.3635\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.3233 - val_loss: 1.3464\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3127 - val_loss: 1.3292\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3063 - val_loss: 1.3120\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3042 - val_loss: 1.2946\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2982 - val_loss: 1.2770\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2899 - val_loss: 1.2595\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2838 - val_loss: 1.2418\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2810 - val_loss: 1.2241\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2717 - val_loss: 1.2063\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2660 - val_loss: 1.1885\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2608 - val_loss: 1.1706\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2556 - val_loss: 1.1527\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0179\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 3s 40ms/step - loss: 0.2368 - val_loss: 1.1815\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2348 - val_loss: 1.1662\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2277 - val_loss: 1.1509\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2262 - val_loss: 1.1354\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2181 - val_loss: 1.1199\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2169 - val_loss: 1.1043\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2130 - val_loss: 1.0884\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2058 - val_loss: 1.0726\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2022 - val_loss: 1.0568\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1967 - val_loss: 1.0409\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1927 - val_loss: 1.0249\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1909 - val_loss: 1.0089\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1837 - val_loss: 0.9928\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1785 - val_loss: 0.9768\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1753 - val_loss: 0.9608\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1715 - val_loss: 0.9446\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1658 - val_loss: 0.9286\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1626 - val_loss: 0.9124\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1569 - val_loss: 0.8963\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1532 - val_loss: 0.8802\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0684\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 4s 41ms/step - loss: 0.1654 - val_loss: 1.1081\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1602 - val_loss: 1.0933\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1584 - val_loss: 1.0784\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1547 - val_loss: 1.0633\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1518 - val_loss: 1.0483\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1494 - val_loss: 1.0331\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1464 - val_loss: 1.0180\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1410 - val_loss: 1.0028\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1406 - val_loss: 0.9876\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1358 - val_loss: 0.9724\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1341 - val_loss: 0.9571\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1303 - val_loss: 0.9419\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1261 - val_loss: 0.9267\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1208 - val_loss: 0.9117\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1188 - val_loss: 0.8966\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1163 - val_loss: 0.8816\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1148 - val_loss: 0.8664\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1113 - val_loss: 0.8513\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1066 - val_loss: 0.8363\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1038 - val_loss: 0.8214\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1375\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 3s 42ms/step - loss: 0.1734 - val_loss: 1.2538\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1713 - val_loss: 1.2419\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1681 - val_loss: 1.2300\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1662 - val_loss: 1.2179\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1635 - val_loss: 1.2058\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1606 - val_loss: 1.1936\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1582 - val_loss: 1.1812\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1556 - val_loss: 1.1688\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1525 - val_loss: 1.1564\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1509 - val_loss: 1.1438\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1477 - val_loss: 1.1313\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1455 - val_loss: 1.1187\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1431 - val_loss: 1.1060\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1402 - val_loss: 1.0933\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1382 - val_loss: 1.0806\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1348 - val_loss: 1.0678\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1322 - val_loss: 1.0550\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.1296 - val_loss: 1.0422\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1276 - val_loss: 1.0293\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1239 - val_loss: 1.0165\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3622\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 5s 11ms/step - loss: 0.0080 - val_loss: 0.0027\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0016 - val_loss: 0.0062\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0012 - val_loss: 0.0077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQnuRh1i-5jo",
        "outputId": "97877e30-7250-401c-830f-e3d3ac55eb60"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 16, 'epochs': 10, 'optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model=grid_search.best_estimator_.model"
      ],
      "metadata": {
        "id": "ETcT6nxD-wyh"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om3D3KrZ-wvE",
        "outputId": "b7af0724-5396-4470-8efc-b8d9393dea6d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f5f6e3fc7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=my_model.predict(testX)"
      ],
      "metadata": {
        "id": "2-8CoZnI_phG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"prediction\\n\", prediction)\n",
        "print(\"\\nPrediction Shape-\",prediction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjLVkJ0D_pd5",
        "outputId": "2fbef676-d7dc-46d7-cc80-313119b3588a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction\n",
            " [[0.91470486]\n",
            " [0.91319793]\n",
            " [0.91175634]\n",
            " [0.9078501 ]\n",
            " [0.9052112 ]\n",
            " [0.903755  ]\n",
            " [0.9025773 ]\n",
            " [0.90243506]\n",
            " [0.904131  ]\n",
            " [0.90624905]\n",
            " [0.90924865]\n",
            " [0.91087765]\n",
            " [0.9113673 ]\n",
            " [0.91151977]\n",
            " [0.911124  ]\n",
            " [0.90980357]\n",
            " [0.9078964 ]\n",
            " [0.90606236]\n",
            " [0.9039331 ]\n",
            " [0.90192753]\n",
            " [0.9010416 ]\n",
            " [0.90044814]\n",
            " [0.90019536]\n",
            " [0.9006033 ]\n",
            " [0.90071094]\n",
            " [0.9002198 ]\n",
            " [0.8991546 ]\n",
            " [0.8958307 ]\n",
            " [0.8941732 ]\n",
            " [0.8958046 ]\n",
            " [0.89740366]\n",
            " [0.8997569 ]\n",
            " [0.9024614 ]\n",
            " [0.9050004 ]\n",
            " [0.90715873]\n",
            " [0.90947235]\n",
            " [0.9112188 ]\n",
            " [0.9118026 ]\n",
            " [0.9123311 ]\n",
            " [0.91206145]\n",
            " [0.9117212 ]\n",
            " [0.91016936]\n",
            " [0.90874285]\n",
            " [0.90469164]\n",
            " [0.90048325]\n",
            " [0.8973019 ]\n",
            " [0.893545  ]\n",
            " [0.89048254]\n",
            " [0.88776046]\n",
            " [0.8867211 ]\n",
            " [0.8867509 ]\n",
            " [0.8856166 ]\n",
            " [0.8837667 ]\n",
            " [0.88254756]\n",
            " [0.8829301 ]\n",
            " [0.8815893 ]\n",
            " [0.8799584 ]\n",
            " [0.87930644]\n",
            " [0.8789865 ]\n",
            " [0.8791016 ]\n",
            " [0.87835276]\n",
            " [0.8765558 ]\n",
            " [0.8725632 ]\n",
            " [0.86928385]\n",
            " [0.8674795 ]\n",
            " [0.8659329 ]\n",
            " [0.86297286]\n",
            " [0.8617105 ]\n",
            " [0.8616296 ]\n",
            " [0.8618879 ]\n",
            " [0.86351025]\n",
            " [0.86490196]\n",
            " [0.8666752 ]\n",
            " [0.86961126]\n",
            " [0.8730413 ]\n",
            " [0.8754752 ]\n",
            " [0.8769104 ]\n",
            " [0.8774778 ]\n",
            " [0.8798802 ]\n",
            " [0.8845178 ]\n",
            " [0.8892402 ]\n",
            " [0.8931163 ]\n",
            " [0.89530665]\n",
            " [0.8945501 ]\n",
            " [0.89218426]\n",
            " [0.88958126]\n",
            " [0.8877362 ]\n",
            " [0.8865139 ]\n",
            " [0.8862842 ]\n",
            " [0.88614726]\n",
            " [0.8854773 ]\n",
            " [0.88596576]\n",
            " [0.8868027 ]\n",
            " [0.8880721 ]\n",
            " [0.8906538 ]\n",
            " [0.89527947]\n",
            " [0.899641  ]\n",
            " [0.903952  ]\n",
            " [0.9072577 ]\n",
            " [0.90974796]\n",
            " [0.9117515 ]\n",
            " [0.9151238 ]\n",
            " [0.9196279 ]\n",
            " [0.92355204]\n",
            " [0.92803836]\n",
            " [0.9317541 ]\n",
            " [0.9351681 ]\n",
            " [0.9374323 ]\n",
            " [0.94156295]\n",
            " [0.94615626]\n",
            " [0.9493609 ]\n",
            " [0.9524982 ]\n",
            " [0.954306  ]\n",
            " [0.9571341 ]\n",
            " [0.9607868 ]\n",
            " [0.9661617 ]\n",
            " [0.9723119 ]\n",
            " [0.9767333 ]\n",
            " [0.9789238 ]\n",
            " [0.9764107 ]\n",
            " [0.9739112 ]\n",
            " [0.9749023 ]\n",
            " [0.97657627]\n",
            " [0.97719467]\n",
            " [0.974939  ]\n",
            " [0.97522223]\n",
            " [0.97851974]\n",
            " [0.9834738 ]\n",
            " [0.98609287]\n",
            " [0.98802567]\n",
            " [0.98870575]\n",
            " [0.99181753]\n",
            " [0.9969824 ]\n",
            " [0.9994453 ]\n",
            " [1.0020524 ]\n",
            " [1.0044482 ]\n",
            " [1.0037183 ]\n",
            " [0.99941283]\n",
            " [0.99158716]\n",
            " [0.9840428 ]\n",
            " [0.9777811 ]\n",
            " [0.97501254]\n",
            " [0.9758487 ]\n",
            " [0.978292  ]\n",
            " [0.9810127 ]\n",
            " [0.9815129 ]\n",
            " [0.9812686 ]\n",
            " [0.9829086 ]\n",
            " [0.98679334]\n",
            " [0.9890185 ]\n",
            " [0.9885517 ]\n",
            " [0.98628664]\n",
            " [0.9833928 ]\n",
            " [0.98199594]\n",
            " [0.979191  ]\n",
            " [0.9759738 ]\n",
            " [0.97560275]\n",
            " [0.97614205]\n",
            " [0.9762824 ]\n",
            " [0.97656405]\n",
            " [0.976003  ]\n",
            " [0.9753696 ]\n",
            " [0.97578055]\n",
            " [0.975953  ]\n",
            " [0.9753342 ]\n",
            " [0.97447634]\n",
            " [0.9765173 ]\n",
            " [0.97981167]\n",
            " [0.9835788 ]\n",
            " [0.98645455]\n",
            " [0.9888521 ]\n",
            " [0.9934013 ]\n",
            " [0.9976508 ]\n",
            " [1.0021818 ]\n",
            " [1.0066408 ]\n",
            " [1.0121202 ]\n",
            " [1.0182152 ]\n",
            " [1.02405   ]\n",
            " [1.028163  ]\n",
            " [1.0336134 ]\n",
            " [1.0400541 ]\n",
            " [1.0420349 ]\n",
            " [1.0423017 ]\n",
            " [1.0404402 ]\n",
            " [1.0385553 ]\n",
            " [1.0404636 ]\n",
            " [1.0517131 ]\n",
            " [1.0647722 ]\n",
            " [1.0756841 ]\n",
            " [1.0838022 ]\n",
            " [1.0914218 ]\n",
            " [1.0965672 ]\n",
            " [1.1002953 ]\n",
            " [1.1080966 ]\n",
            " [1.1153805 ]\n",
            " [1.1208503 ]\n",
            " [1.1241214 ]\n",
            " [1.1242127 ]\n",
            " [1.1255313 ]\n",
            " [1.1288736 ]\n",
            " [1.1334956 ]\n",
            " [1.1360757 ]\n",
            " [1.1382306 ]\n",
            " [1.1436175 ]\n",
            " [1.1457638 ]\n",
            " [1.1469331 ]\n",
            " [1.150219  ]\n",
            " [1.1556792 ]\n",
            " [1.1586689 ]\n",
            " [1.1543635 ]\n",
            " [1.1491271 ]\n",
            " [1.1422895 ]\n",
            " [1.1350503 ]\n",
            " [1.1322773 ]\n",
            " [1.1323192 ]\n",
            " [1.130262  ]\n",
            " [1.129852  ]\n",
            " [1.1306297 ]\n",
            " [1.1326776 ]\n",
            " [1.1351476 ]\n",
            " [1.1507578 ]\n",
            " [1.1746428 ]\n",
            " [1.197761  ]\n",
            " [1.2258948 ]\n",
            " [1.2567842 ]\n",
            " [1.2791011 ]\n",
            " [1.2892587 ]\n",
            " [1.2953997 ]\n",
            " [1.298112  ]\n",
            " [1.2939003 ]\n",
            " [1.2851346 ]\n",
            " [1.2756935 ]\n",
            " [1.2783587 ]\n",
            " [1.2874197 ]\n",
            " [1.2957997 ]\n",
            " [1.3022702 ]\n",
            " [1.302569  ]\n",
            " [1.2960079 ]\n",
            " [1.2900711 ]\n",
            " [1.2857933 ]\n",
            " [1.2833978 ]\n",
            " [1.282684  ]\n",
            " [1.2888061 ]\n",
            " [1.2963469 ]\n",
            " [1.3028448 ]\n",
            " [1.3025435 ]\n",
            " [1.3016855 ]\n",
            " [1.3009317 ]\n",
            " [1.297639  ]\n",
            " [1.288936  ]\n",
            " [1.283194  ]\n",
            " [1.2823197 ]\n",
            " [1.2850814 ]\n",
            " [1.2859054 ]\n",
            " [1.2875679 ]\n",
            " [1.2880684 ]\n",
            " [1.2894576 ]\n",
            " [1.3018473 ]\n",
            " [1.3203379 ]\n",
            " [1.3314233 ]\n",
            " [1.3411124 ]\n",
            " [1.3454895 ]\n",
            " [1.344298  ]\n",
            " [1.3405792 ]\n",
            " [1.3366805 ]\n",
            " [1.3338323 ]\n",
            " [1.3350583 ]\n",
            " [1.3345524 ]\n",
            " [1.33406   ]\n",
            " [1.3280002 ]\n",
            " [1.3239719 ]\n",
            " [1.3211235 ]\n",
            " [1.3205075 ]\n",
            " [1.3233477 ]\n",
            " [1.3242282 ]\n",
            " [1.3249089 ]\n",
            " [1.3281153 ]\n",
            " [1.330953  ]\n",
            " [1.3331898 ]\n",
            " [1.3273395 ]\n",
            " [1.3115649 ]\n",
            " [1.2853781 ]\n",
            " [1.2639263 ]\n",
            " [1.2411178 ]\n",
            " [1.225381  ]\n",
            " [1.2211075 ]\n",
            " [1.217513  ]\n",
            " [1.2164059 ]\n",
            " [1.2172562 ]\n",
            " [1.2217968 ]\n",
            " [1.2259568 ]\n",
            " [1.2245133 ]\n",
            " [1.2198366 ]\n",
            " [1.21794   ]\n",
            " [1.2155232 ]\n",
            " [1.2123363 ]\n",
            " [1.2062305 ]\n",
            " [1.1958767 ]\n",
            " [1.1810639 ]\n",
            " [1.1709409 ]\n",
            " [1.1588743 ]\n",
            " [1.1506807 ]\n",
            " [1.1457858 ]\n",
            " [1.141606  ]\n",
            " [1.1399183 ]\n",
            " [1.1374822 ]\n",
            " [1.1366313 ]\n",
            " [1.135768  ]\n",
            " [1.1345797 ]\n",
            " [1.1343557 ]\n",
            " [1.1292121 ]\n",
            " [1.120967  ]\n",
            " [1.118438  ]\n",
            " [1.1234823 ]\n",
            " [1.1310949 ]\n",
            " [1.1369338 ]\n",
            " [1.1394746 ]\n",
            " [1.1398313 ]\n",
            " [1.1401491 ]\n",
            " [1.1471564 ]\n",
            " [1.1556704 ]\n",
            " [1.1700606 ]\n",
            " [1.1840974 ]\n",
            " [1.1925495 ]\n",
            " [1.1995015 ]\n",
            " [1.207623  ]\n",
            " [1.2126526 ]\n",
            " [1.2199183 ]\n",
            " [1.225525  ]\n",
            " [1.2285827 ]\n",
            " [1.2291367 ]\n",
            " [1.2308292 ]\n",
            " [1.2358872 ]\n",
            " [1.2395458 ]\n",
            " [1.238933  ]\n",
            " [1.236023  ]\n",
            " [1.2302667 ]\n",
            " [1.2213314 ]\n",
            " [1.2183115 ]\n",
            " [1.220642  ]\n",
            " [1.2222172 ]\n",
            " [1.2230537 ]\n",
            " [1.2250543 ]\n",
            " [1.2256751 ]\n",
            " [1.2271    ]\n",
            " [1.2306871 ]\n",
            " [1.2338377 ]\n",
            " [1.2350125 ]\n",
            " [1.236438  ]\n",
            " [1.2392967 ]\n",
            " [1.2404518 ]\n",
            " [1.2330737 ]\n",
            " [1.2234012 ]\n",
            " [1.2128434 ]\n",
            " [1.2046564 ]\n",
            " [1.1932012 ]\n",
            " [1.1849624 ]\n",
            " [1.1893926 ]\n",
            " [1.1975187 ]\n",
            " [1.2023934 ]\n",
            " [1.2090869 ]\n",
            " [1.2184315 ]\n",
            " [1.2307739 ]\n",
            " [1.2431136 ]\n",
            " [1.253912  ]\n",
            " [1.2629793 ]\n",
            " [1.2706621 ]\n",
            " [1.274363  ]\n",
            " [1.2779375 ]\n",
            " [1.282476  ]\n",
            " [1.2850714 ]\n",
            " [1.2821597 ]\n",
            " [1.2753003 ]\n",
            " [1.2663656 ]\n",
            " [1.2554988 ]\n",
            " [1.2471889 ]\n",
            " [1.2481536 ]\n",
            " [1.2412899 ]\n",
            " [1.2370639 ]\n",
            " [1.2325801 ]\n",
            " [1.2291532 ]\n",
            " [1.2260649 ]\n",
            " [1.2223884 ]\n",
            " [1.2184187 ]\n",
            " [1.2069923 ]\n",
            " [1.1985698 ]\n",
            " [1.1891774 ]\n",
            " [1.1827551 ]\n",
            " [1.1800449 ]\n",
            " [1.1864887 ]\n",
            " [1.189992  ]\n",
            " [1.1925889 ]\n",
            " [1.1925015 ]\n",
            " [1.1941597 ]\n",
            " [1.1975379 ]\n",
            " [1.2039114 ]\n",
            " [1.2053446 ]\n",
            " [1.205317  ]\n",
            " [1.2050649 ]\n",
            " [1.2003499 ]\n",
            " [1.1944239 ]\n",
            " [1.1889367 ]\n",
            " [1.1844158 ]\n",
            " [1.1800349 ]\n",
            " [1.175316  ]\n",
            " [1.1708561 ]\n",
            " [1.1695365 ]\n",
            " [1.168987  ]\n",
            " [1.1698613 ]\n",
            " [1.172768  ]\n",
            " [1.1771121 ]\n",
            " [1.1808205 ]\n",
            " [1.1936263 ]\n",
            " [1.2064551 ]\n",
            " [1.2120291 ]\n",
            " [1.2119404 ]\n",
            " [1.2078367 ]\n",
            " [1.2019893 ]\n",
            " [1.1895441 ]\n",
            " [1.177783  ]\n",
            " [1.1695486 ]\n",
            " [1.1630142 ]\n",
            " [1.1546599 ]\n",
            " [1.1472912 ]\n",
            " [1.143847  ]\n",
            " [1.143249  ]\n",
            " [1.1343753 ]\n",
            " [1.1252432 ]\n",
            " [1.1181347 ]\n",
            " [1.1137526 ]\n",
            " [1.1128191 ]\n",
            " [1.1100792 ]\n",
            " [1.111218  ]\n",
            " [1.1204348 ]\n",
            " [1.1311042 ]\n",
            " [1.1420665 ]\n",
            " [1.1523114 ]\n",
            " [1.163304  ]\n",
            " [1.1671999 ]\n",
            " [1.167289  ]\n",
            " [1.1643233 ]\n",
            " [1.1598527 ]\n",
            " [1.1594269 ]\n",
            " [1.1625391 ]\n",
            " [1.1691101 ]\n",
            " [1.1764686 ]\n",
            " [1.1809391 ]\n",
            " [1.1818631 ]\n",
            " [1.1817521 ]\n",
            " [1.1781085 ]\n",
            " [1.1744142 ]\n",
            " [1.1731101 ]\n",
            " [1.1757563 ]\n",
            " [1.1795241 ]\n",
            " [1.1822649 ]\n",
            " [1.1829312 ]\n",
            " [1.183493  ]\n",
            " [1.1817943 ]\n",
            " [1.1782172 ]\n",
            " [1.175557  ]\n",
            " [1.1757183 ]\n",
            " [1.1742724 ]\n",
            " [1.1717913 ]\n",
            " [1.1710104 ]\n",
            " [1.1723462 ]\n",
            " [1.174227  ]\n",
            " [1.1769272 ]\n",
            " [1.1825112 ]\n",
            " [1.1850224 ]\n",
            " [1.1867778 ]\n",
            " [1.1852918 ]\n",
            " [1.1830901 ]\n",
            " [1.1811374 ]\n",
            " [1.1798116 ]\n",
            " [1.176611  ]\n",
            " [1.1746343 ]\n",
            " [1.1730986 ]\n",
            " [1.1714536 ]\n",
            " [1.170237  ]\n",
            " [1.1706146 ]\n",
            " [1.1739506 ]\n",
            " [1.1784146 ]\n",
            " [1.1808028 ]\n",
            " [1.1848651 ]\n",
            " [1.1882937 ]\n",
            " [1.1910644 ]\n",
            " [1.1951319 ]\n",
            " [1.1940694 ]\n",
            " [1.1926303 ]\n",
            " [1.1891208 ]\n",
            " [1.18521   ]\n",
            " [1.1842006 ]\n",
            " [1.1848531 ]\n",
            " [1.1858264 ]\n",
            " [1.1873428 ]\n",
            " [1.1879947 ]\n",
            " [1.1872615 ]\n",
            " [1.1872286 ]\n",
            " [1.1885134 ]\n",
            " [1.1899923 ]\n",
            " [1.1905153 ]\n",
            " [1.1922998 ]\n",
            " [1.1952602 ]\n",
            " [1.1974732 ]\n",
            " [1.2017499 ]\n",
            " [1.2076108 ]\n",
            " [1.2131873 ]\n",
            " [1.2169877 ]\n",
            " [1.218676  ]\n",
            " [1.217098  ]\n",
            " [1.2145468 ]\n",
            " [1.2129643 ]\n",
            " [1.2126956 ]\n",
            " [1.210714  ]\n",
            " [1.20594   ]\n",
            " [1.1989149 ]\n",
            " [1.1930245 ]\n",
            " [1.1873668 ]\n",
            " [1.1816493 ]\n",
            " [1.1774138 ]\n",
            " [1.1731563 ]\n",
            " [1.1677158 ]\n",
            " [1.1614847 ]\n",
            " [1.1570375 ]\n",
            " [1.1510594 ]\n",
            " [1.1448152 ]\n",
            " [1.1428847 ]\n",
            " [1.145899  ]\n",
            " [1.1484196 ]\n",
            " [1.1494288 ]\n",
            " [1.1495798 ]\n",
            " [1.1498988 ]\n",
            " [1.1532595 ]\n",
            " [1.1567135 ]\n",
            " [1.159836  ]\n",
            " [1.1634576 ]\n",
            " [1.1674864 ]\n",
            " [1.1689861 ]\n",
            " [1.1687534 ]\n",
            " [1.1664782 ]\n",
            " [1.163787  ]\n",
            " [1.1645368 ]\n",
            " [1.1695054 ]\n",
            " [1.1776272 ]\n",
            " [1.1870875 ]\n",
            " [1.1953572 ]\n",
            " [1.2005855 ]\n",
            " [1.2029679 ]\n",
            " [1.2048947 ]\n",
            " [1.2062763 ]\n",
            " [1.2100724 ]\n",
            " [1.2098364 ]\n",
            " [1.2068179 ]\n",
            " [1.2035525 ]\n",
            " [1.2004085 ]\n",
            " [1.1977769 ]\n",
            " [1.1940356 ]\n",
            " [1.1923437 ]\n",
            " [1.1921554 ]\n",
            " [1.1902122 ]\n",
            " [1.187752  ]\n",
            " [1.186331  ]\n",
            " [1.1847041 ]\n",
            " [1.1835626 ]\n",
            " [1.1826676 ]\n",
            " [1.1822834 ]\n",
            " [1.1818123 ]\n",
            " [1.1817935 ]\n",
            " [1.179693  ]\n",
            " [1.177351  ]\n",
            " [1.1752357 ]\n",
            " [1.1733017 ]\n",
            " [1.166718  ]\n",
            " [1.1589875 ]\n",
            " [1.1503427 ]\n",
            " [1.1412876 ]\n",
            " [1.1299367 ]\n",
            " [1.1196692 ]\n",
            " [1.1059266 ]\n",
            " [1.094866  ]\n",
            " [1.0819039 ]\n",
            " [1.0727739 ]\n",
            " [1.0689203 ]\n",
            " [1.066026  ]\n",
            " [1.0652734 ]\n",
            " [1.062175  ]\n",
            " [1.0603791 ]\n",
            " [1.0529386 ]\n",
            " [1.0439655 ]\n",
            " [1.0364468 ]\n",
            " [1.0386647 ]\n",
            " [1.0503876 ]\n",
            " [1.0610434 ]\n",
            " [1.066684  ]\n",
            " [1.0720685 ]\n",
            " [1.0802493 ]\n",
            " [1.0887222 ]\n",
            " [1.0975332 ]\n",
            " [1.1076543 ]\n",
            " [1.1171212 ]\n",
            " [1.1246936 ]\n",
            " [1.1294885 ]\n",
            " [1.1393589 ]\n",
            " [1.1495489 ]\n",
            " [1.1512463 ]\n",
            " [1.1476622 ]\n",
            " [1.1431829 ]\n",
            " [1.1401508 ]\n",
            " [1.1404366 ]\n",
            " [1.1404662 ]\n",
            " [1.1414385 ]\n",
            " [1.142025  ]\n",
            " [1.1433303 ]\n",
            " [1.1426556 ]\n",
            " [1.1411974 ]\n",
            " [1.139003  ]\n",
            " [1.1380624 ]\n",
            " [1.1383092 ]\n",
            " [1.1386532 ]\n",
            " [1.1383634 ]\n",
            " [1.1348329 ]\n",
            " [1.1339225 ]\n",
            " [1.1337891 ]\n",
            " [1.1338137 ]\n",
            " [1.1314685 ]\n",
            " [1.1291773 ]\n",
            " [1.1267369 ]\n",
            " [1.1266792 ]\n",
            " [1.1276791 ]\n",
            " [1.1279256 ]\n",
            " [1.127976  ]\n",
            " [1.1281595 ]\n",
            " [1.131649  ]\n",
            " [1.1359501 ]\n",
            " [1.1391845 ]\n",
            " [1.142689  ]\n",
            " [1.1473508 ]\n",
            " [1.1502347 ]\n",
            " [1.1534305 ]\n",
            " [1.1549673 ]\n",
            " [1.154136  ]\n",
            " [1.1527514 ]\n",
            " [1.150938  ]\n",
            " [1.147583  ]\n",
            " [1.1438758 ]\n",
            " [1.1397791 ]\n",
            " [1.1323656 ]\n",
            " [1.1219444 ]\n",
            " [1.1131793 ]\n",
            " [1.1067233 ]\n",
            " [1.1031104 ]\n",
            " [1.1008736 ]\n",
            " [1.0998728 ]\n",
            " [1.1000004 ]\n",
            " [1.0996141 ]\n",
            " [1.0962203 ]\n",
            " [1.0889182 ]\n",
            " [1.0825677 ]\n",
            " [1.0775702 ]\n",
            " [1.0746195 ]\n",
            " [1.0715506 ]\n",
            " [1.072535  ]\n",
            " [1.0812831 ]\n",
            " [1.0884502 ]\n",
            " [1.0948553 ]\n",
            " [1.1042794 ]\n",
            " [1.1104914 ]\n",
            " [1.1162026 ]\n",
            " [1.1224433 ]\n",
            " [1.1256292 ]\n",
            " [1.1265019 ]\n",
            " [1.1278453 ]\n",
            " [1.1274126 ]\n",
            " [1.1260581 ]\n",
            " [1.1294105 ]\n",
            " [1.13971   ]\n",
            " [1.1525712 ]\n",
            " [1.1644797 ]\n",
            " [1.1733447 ]\n",
            " [1.1786909 ]\n",
            " [1.1810108 ]\n",
            " [1.1816865 ]\n",
            " [1.1790069 ]\n",
            " [1.1736343 ]\n",
            " [1.1694862 ]\n",
            " [1.167061  ]\n",
            " [1.1662016 ]\n",
            " [1.167159  ]\n",
            " [1.1684437 ]\n",
            " [1.1663756 ]\n",
            " [1.1620464 ]\n",
            " [1.1500295 ]\n",
            " [1.1377913 ]\n",
            " [1.1268032 ]\n",
            " [1.1177819 ]\n",
            " [1.1100987 ]\n",
            " [1.1021044 ]\n",
            " [1.0960829 ]\n",
            " [1.0932878 ]\n",
            " [1.0948764 ]\n",
            " [1.0969816 ]\n",
            " [1.0969763 ]\n",
            " [1.0972047 ]\n",
            " [1.0965948 ]\n",
            " [1.09572   ]\n",
            " [1.0944974 ]\n",
            " [1.09269   ]\n",
            " [1.0955843 ]\n",
            " [1.1028204 ]\n",
            " [1.1095058 ]\n",
            " [1.1086465 ]\n",
            " [1.104028  ]\n",
            " [1.0940409 ]\n",
            " [1.0839028 ]\n",
            " [1.0629238 ]\n",
            " [1.0440435 ]\n",
            " [1.0337142 ]\n",
            " [1.0257955 ]\n",
            " [1.0199363 ]\n",
            " [1.0092614 ]\n",
            " [0.9545307 ]\n",
            " [0.89966536]\n",
            " [0.8535044 ]\n",
            " [0.8057489 ]\n",
            " [0.76738   ]\n",
            " [0.73671865]\n",
            " [0.7127117 ]\n",
            " [0.6962804 ]\n",
            " [0.68237907]\n",
            " [0.6869365 ]\n",
            " [0.6917056 ]\n",
            " [0.70415187]\n",
            " [0.72710043]\n",
            " [0.751894  ]\n",
            " [0.7695432 ]\n",
            " [0.77663916]\n",
            " [0.7843251 ]\n",
            " [0.7905631 ]\n",
            " [0.806971  ]\n",
            " [0.83529574]\n",
            " [0.87624526]\n",
            " [0.906226  ]\n",
            " [0.9260304 ]\n",
            " [0.93757325]\n",
            " [0.94376796]\n",
            " [0.9482628 ]\n",
            " [0.94797325]\n",
            " [0.93648535]\n",
            " [0.925589  ]\n",
            " [0.91971356]\n",
            " [0.91259885]\n",
            " [0.90233296]\n",
            " [0.89566696]\n",
            " [0.8923654 ]\n",
            " [0.89080614]\n",
            " [0.88747245]\n",
            " [0.8867303 ]\n",
            " [0.893266  ]\n",
            " [0.900073  ]\n",
            " [0.9034645 ]\n",
            " [0.90846825]\n",
            " [0.9150216 ]\n",
            " [0.9233109 ]\n",
            " [0.9310355 ]\n",
            " [0.9346363 ]\n",
            " [0.93669647]\n",
            " [0.9399702 ]\n",
            " [0.9452113 ]\n",
            " [0.9504283 ]\n",
            " [0.95622545]\n",
            " [0.95599043]\n",
            " [0.95533925]\n",
            " [0.95716584]\n",
            " [0.95773757]\n",
            " [0.95436126]\n",
            " [0.9489265 ]\n",
            " [0.94624764]\n",
            " [0.9481435 ]\n",
            " [0.95698667]\n",
            " [0.972551  ]\n",
            " [0.9958916 ]\n",
            " [1.0102648 ]\n",
            " [1.0196757 ]\n",
            " [1.0223708 ]\n",
            " [1.0159068 ]\n",
            " [1.003976  ]\n",
            " [0.9982448 ]\n",
            " [0.9943164 ]\n",
            " [0.9913556 ]\n",
            " [0.99188286]\n",
            " [0.99466306]\n",
            " [0.99958974]\n",
            " [0.9995624 ]\n",
            " [0.99497306]\n",
            " [0.99015254]\n",
            " [0.98522985]\n",
            " [0.9843876 ]\n",
            " [0.98732805]\n",
            " [0.99422395]\n",
            " [1.0028775 ]\n",
            " [1.0154929 ]\n",
            " [1.0238785 ]\n",
            " [1.0284925 ]\n",
            " [1.0262685 ]\n",
            " [1.0189581 ]\n",
            " [1.0111916 ]\n",
            " [1.0085008 ]\n",
            " [1.0059563 ]\n",
            " [1.0060467 ]\n",
            " [1.0065582 ]\n",
            " [1.014195  ]\n",
            " [1.0208427 ]\n",
            " [1.0266039 ]\n",
            " [1.0263958 ]\n",
            " [1.0237563 ]\n",
            " [1.01865   ]\n",
            " [1.0156875 ]\n",
            " [1.013494  ]\n",
            " [1.0099721 ]\n",
            " [1.0096908 ]\n",
            " [1.0104932 ]\n",
            " [1.0089867 ]\n",
            " [1.0054804 ]\n",
            " [1.0006009 ]\n",
            " [0.9984963 ]\n",
            " [0.9958157 ]\n",
            " [0.9944719 ]\n",
            " [0.9939091 ]\n",
            " [0.99103856]\n",
            " [0.9830546 ]\n",
            " [0.9753772 ]\n",
            " [0.96963245]\n",
            " [0.968183  ]\n",
            " [0.9674629 ]\n",
            " [0.9686434 ]\n",
            " [0.96821046]\n",
            " [0.96417236]\n",
            " [0.9599898 ]\n",
            " [0.9572449 ]\n",
            " [0.9540499 ]\n",
            " [0.9468025 ]\n",
            " [0.938681  ]\n",
            " [0.9333563 ]\n",
            " [0.9287271 ]\n",
            " [0.9253169 ]\n",
            " [0.9231328 ]\n",
            " [0.92255586]\n",
            " [0.9244035 ]\n",
            " [0.92561466]\n",
            " [0.9252649 ]\n",
            " [0.9209516 ]\n",
            " [0.9130897 ]\n",
            " [0.9001458 ]\n",
            " [0.88688314]\n",
            " [0.87895805]\n",
            " [0.87424695]\n",
            " [0.86716706]\n",
            " [0.86359787]\n",
            " [0.8594905 ]\n",
            " [0.8562704 ]\n",
            " [0.8569725 ]\n",
            " [0.85881186]\n",
            " [0.86202383]\n",
            " [0.86596847]\n",
            " [0.8733219 ]\n",
            " [0.87776613]\n",
            " [0.87919146]\n",
            " [0.8780858 ]\n",
            " [0.87472546]\n",
            " [0.86930734]\n",
            " [0.86434376]\n",
            " [0.85994905]\n",
            " [0.856359  ]\n",
            " [0.852984  ]\n",
            " [0.848791  ]\n",
            " [0.8418659 ]\n",
            " [0.83518386]\n",
            " [0.82952267]\n",
            " [0.8317149 ]\n",
            " [0.83723634]\n",
            " [0.8492068 ]\n",
            " [0.8624332 ]\n",
            " [0.8783085 ]\n",
            " [0.90640634]\n",
            " [0.9357152 ]\n",
            " [0.95689744]\n",
            " [0.9720552 ]\n",
            " [0.98350567]\n",
            " [0.9903484 ]\n",
            " [0.995267  ]\n",
            " [0.9985007 ]\n",
            " [1.0017529 ]\n",
            " [1.0135957 ]\n",
            " [1.0264413 ]\n",
            " [1.0427222 ]\n",
            " [1.06003   ]\n",
            " [1.0741785 ]\n",
            " [1.0771234 ]\n",
            " [1.079184  ]\n",
            " [1.0797012 ]\n",
            " [1.0846785 ]\n",
            " [1.0946008 ]\n",
            " [1.1050432 ]\n",
            " [1.1135623 ]\n",
            " [1.1170061 ]\n",
            " [1.1188273 ]\n",
            " [1.1195501 ]\n",
            " [1.1183476 ]\n",
            " [1.1182307 ]\n",
            " [1.1087291 ]\n",
            " [1.0996382 ]\n",
            " [1.0889102 ]\n",
            " [1.0829082 ]\n",
            " [1.0826983 ]\n",
            " [1.0815268 ]\n",
            " [1.0849887 ]]\n",
            "\n",
            "Prediction Shape- (916, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs7vvhLr_pa5",
        "outputId": "176ce8bb-2e83-4394-8c00-ff405f9142ca"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(916, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_copies_array = np.repeat(prediction,5, axis=-1)"
      ],
      "metadata": {
        "id": "ZmiXD23y_pXj"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_copies_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS4-FVNlAIcj",
        "outputId": "ebc0c28b-d346-4fd8-ce7d-9c6003584ce6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(916, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_copies_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-pdOkBjAITk",
        "outputId": "1a7134b9-3ac6-4dc4-f577-82bbc9e5f41a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.91470486, 0.91470486, 0.91470486, 0.91470486, 0.91470486],\n",
              "       [0.91319793, 0.91319793, 0.91319793, 0.91319793, 0.91319793],\n",
              "       [0.91175634, 0.91175634, 0.91175634, 0.91175634, 0.91175634],\n",
              "       ...,\n",
              "       [1.0826983 , 1.0826983 , 1.0826983 , 1.0826983 , 1.0826983 ],\n",
              "       [1.0815268 , 1.0815268 , 1.0815268 , 1.0815268 , 1.0815268 ],\n",
              "       [1.0849887 , 1.0849887 , 1.0849887 , 1.0849887 , 1.0849887 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=scaler.inverse_transform(np.reshape(prediction_copies_array,(len(prediction),5)))[:,-1]"
      ],
      "metadata": {
        "id": "VrWWoJqFAIP9"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6FcVLOPAIMT",
        "outputId": "deba28ef-f476-4d17-e802-743ccd53ddeb"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([31.270653, 31.221369, 31.174221, 31.046467, 30.960163, 30.912539,\n",
              "       30.874022, 30.86937 , 30.924835, 30.994106, 31.092207, 31.145483,\n",
              "       31.161497, 31.166483, 31.15354 , 31.110355, 31.047981, 30.988   ,\n",
              "       30.918364, 30.852772, 30.823797, 30.804388, 30.79612 , 30.809462,\n",
              "       30.812983, 30.796919, 30.762083, 30.653374, 30.599167, 30.652521,\n",
              "       30.704819, 30.78178 , 30.870232, 30.953268, 31.023857, 31.099524,\n",
              "       31.156641, 31.175734, 31.193018, 31.1842  , 31.173073, 31.122318,\n",
              "       31.075665, 30.94317 , 30.805536, 30.70149 , 30.57862 , 30.478464,\n",
              "       30.389439, 30.355446, 30.35642 , 30.319324, 30.258823, 30.218952,\n",
              "       30.231462, 30.18761 , 30.134274, 30.112951, 30.102488, 30.10625 ,\n",
              "       30.08176 , 30.022991, 29.892414, 29.785164, 29.726152, 29.67557 ,\n",
              "       29.578764, 29.537477, 29.534832, 29.54328 , 29.596338, 29.641853,\n",
              "       29.699848, 29.795872, 29.908049, 29.987652, 30.034588, 30.053146,\n",
              "       30.131716, 30.283388, 30.437834, 30.5646  , 30.636236, 30.611492,\n",
              "       30.534119, 30.448988, 30.388645, 30.34867 , 30.341156, 30.33668 ,\n",
              "       30.314768, 30.330744, 30.358114, 30.39963 , 30.484064, 30.635347,\n",
              "       30.77799 , 30.918982, 31.027092, 31.108538, 31.174063, 31.284353,\n",
              "       31.43166 , 31.559998, 31.706722, 31.828245, 31.9399  , 32.01395 ,\n",
              "       32.149044, 32.299267, 32.404076, 32.50668 , 32.565804, 32.658295,\n",
              "       32.777756, 32.95354 , 33.154682, 33.299286, 33.370926, 33.28873 ,\n",
              "       33.206985, 33.239403, 33.294147, 33.314373, 33.2406  , 33.249866,\n",
              "       33.357708, 33.51973 , 33.605385, 33.6686  , 33.69084 , 33.79261 ,\n",
              "       33.961525, 34.04208 , 34.127342, 34.205696, 34.181824, 34.041016,\n",
              "       33.78508 , 33.53834 , 33.33355 , 33.243008, 33.27035 , 33.35026 ,\n",
              "       33.439243, 33.4556  , 33.44761 , 33.501247, 33.628296, 33.70107 ,\n",
              "       33.685802, 33.611725, 33.51708 , 33.471397, 33.37966 , 33.274445,\n",
              "       33.26231 , 33.27995 , 33.28454 , 33.29375 , 33.2754  , 33.254684,\n",
              "       33.268124, 33.273766, 33.253525, 33.22547 , 33.29222 , 33.399963,\n",
              "       33.523167, 33.617214, 33.695625, 33.84441 , 33.983387, 34.131573,\n",
              "       34.277405, 34.45661 , 34.655945, 34.84677 , 34.981285, 35.159542,\n",
              "       35.370182, 35.434963, 35.44369 , 35.382812, 35.321163, 35.383575,\n",
              "       35.75149 , 36.17859 , 36.535458, 36.80096 , 37.05016 , 37.218437,\n",
              "       37.340366, 37.595505, 37.833725, 38.012615, 38.119595, 38.12258 ,\n",
              "       38.165707, 38.275013, 38.426174, 38.51056 , 38.58103 , 38.757214,\n",
              "       38.827404, 38.865646, 38.97311 , 39.151688, 39.249466, 39.108658,\n",
              "       38.937405, 38.71378 , 38.477024, 38.38633 , 38.387703, 38.320423,\n",
              "       38.307014, 38.332447, 38.39942 , 38.480206, 38.990734, 39.77189 ,\n",
              "       40.52797 , 41.448082, 42.458317, 43.188187, 43.52039 , 43.72123 ,\n",
              "       43.809937, 43.67219 , 43.38551 , 43.076744, 43.163906, 43.460243,\n",
              "       43.734314, 43.945927, 43.955704, 43.74112 , 43.54696 , 43.407055,\n",
              "       43.32871 , 43.305363, 43.50559 , 43.75221 , 43.96472 , 43.95487 ,\n",
              "       43.926804, 43.902153, 43.794468, 43.50984 , 43.322044, 43.29345 ,\n",
              "       43.38377 , 43.41072 , 43.46509 , 43.48146 , 43.526894, 43.9321  ,\n",
              "       44.53683 , 44.899376, 45.21626 , 45.35941 , 45.320442, 45.19882 ,\n",
              "       45.071316, 44.97816 , 45.01826 , 45.001717, 44.98561 , 44.787426,\n",
              "       44.655678, 44.562523, 44.542377, 44.635265, 44.664062, 44.686325,\n",
              "       44.79119 , 44.883995, 44.957153, 44.76582 , 44.249912, 43.393475,\n",
              "       42.691895, 41.94595 , 41.43128 , 41.29151 , 41.173954, 41.137745,\n",
              "       41.165558, 41.314056, 41.450108, 41.4029  , 41.249947, 41.18792 ,\n",
              "       41.10888 , 41.00465 , 40.804962, 40.466343, 39.98189 , 39.650818,\n",
              "       39.256184, 38.988213, 38.828125, 38.691425, 38.63623 , 38.556557,\n",
              "       38.52873 , 38.500496, 38.46163 , 38.454304, 38.286087, 38.01643 ,\n",
              "       37.93372 , 38.098694, 38.347664, 38.538624, 38.62172 , 38.633385,\n",
              "       38.64378 , 38.87295 , 39.1514  , 39.622032, 40.081104, 40.357525,\n",
              "       40.584892, 40.850506, 41.014996, 41.252617, 41.435986, 41.535988,\n",
              "       41.554108, 41.609463, 41.77488 , 41.894535, 41.874493, 41.77932 ,\n",
              "       41.591064, 41.298836, 41.200073, 41.276287, 41.327805, 41.355164,\n",
              "       41.420593, 41.440895, 41.4875  , 41.604813, 41.707855, 41.746277,\n",
              "       41.792896, 41.886387, 41.924168, 41.682865, 41.366528, 41.021236,\n",
              "       40.75348 , 40.37884 , 40.10939 , 40.25428 , 40.520042, 40.67947 ,\n",
              "       40.89838 , 41.203995, 41.60765 , 42.011223, 42.36438 , 42.660923,\n",
              "       42.91219 , 43.03323 , 43.15013 , 43.29856 , 43.383442, 43.288216,\n",
              "       43.06388 , 42.771675, 42.416275, 42.144505, 42.176052, 41.951576,\n",
              "       41.813366, 41.66672 , 41.554646, 41.453644, 41.333405, 41.203575,\n",
              "       40.829876, 40.55442 , 40.247242, 40.0372  , 39.948566, 40.15931 ,\n",
              "       40.273884, 40.358818, 40.355957, 40.41019 , 40.52067 , 40.72912 ,\n",
              "       40.77599 , 40.775085, 40.76684 , 40.61264 , 40.41883 , 40.239372,\n",
              "       40.091515, 39.94824 , 39.793907, 39.64805 , 39.60489 , 39.586918,\n",
              "       39.615513, 39.710575, 39.85265 , 39.97393 , 40.392742, 40.81231 ,\n",
              "       40.994606, 40.991703, 40.857494, 40.666256, 40.259235, 39.87459 ,\n",
              "       39.605286, 39.39158 , 39.11835 , 38.877357, 38.764717, 38.745163,\n",
              "       38.45495 , 38.15628 , 37.9238  , 37.780483, 37.749954, 37.660343,\n",
              "       37.69759 , 37.999023, 38.347965, 38.706486, 39.041546, 39.401054,\n",
              "       39.52847 , 39.531387, 39.434395, 39.288185, 39.274258, 39.37604 ,\n",
              "       39.590942, 39.831604, 39.97781 , 40.00803 , 40.0044  , 39.885235,\n",
              "       39.764412, 39.721764, 39.808308, 39.93153 , 40.02117 , 40.04296 ,\n",
              "       40.061337, 40.00578 , 39.88879 , 39.80179 , 39.807064, 39.759777,\n",
              "       39.678635, 39.65309 , 39.69678 , 39.758293, 39.846603, 40.029224,\n",
              "       40.11135 , 40.168766, 40.120163, 40.048157, 39.9843  , 39.940937,\n",
              "       39.836258, 39.771614, 39.721386, 39.667587, 39.627796, 39.64015 ,\n",
              "       39.749252, 39.895245, 39.973354, 40.10621 , 40.21834 , 40.308956,\n",
              "       40.441982, 40.407234, 40.36017 , 40.24539 , 40.11749 , 40.08448 ,\n",
              "       40.105816, 40.13765 , 40.18724 , 40.208565, 40.18458 , 40.183506,\n",
              "       40.22553 , 40.273895, 40.290997, 40.34936 , 40.44618 , 40.518555,\n",
              "       40.658424, 40.850105, 41.032486, 41.156776, 41.21199 , 41.16038 ,\n",
              "       41.076946, 41.025192, 41.016403, 40.951595, 40.795464, 40.565704,\n",
              "       40.373062, 40.18803 , 40.001038, 39.86252 , 39.723274, 39.545345,\n",
              "       39.341557, 39.19611 , 39.0006  , 38.796383, 38.733246, 38.83183 ,\n",
              "       38.914265, 38.94727 , 38.952206, 38.96264 , 39.07255 , 39.185516,\n",
              "       39.28764 , 39.406082, 39.53784 , 39.586887, 39.579277, 39.504868,\n",
              "       39.416855, 39.441376, 39.60387 , 39.869495, 40.178894, 40.449352,\n",
              "       40.620342, 40.698257, 40.761272, 40.80646 , 40.93061 , 40.922894,\n",
              "       40.824173, 40.717377, 40.61455 , 40.52849 , 40.40613 , 40.350796,\n",
              "       40.344635, 40.281086, 40.200626, 40.154152, 40.100945, 40.063614,\n",
              "       40.03434 , 40.021774, 40.006367, 40.005753, 39.937057, 39.860462,\n",
              "       39.791283, 39.72803 , 39.51271 , 39.259888, 38.977158, 38.68101 ,\n",
              "       38.309784, 37.973988, 37.524536, 37.1628  , 36.738876, 36.44028 ,\n",
              "       36.314247, 36.21959 , 36.194977, 36.093647, 36.034912, 35.79157 ,\n",
              "       35.498104, 35.25221 , 35.324745, 35.70814 , 36.056637, 36.24111 ,\n",
              "       36.41721 , 36.684765, 36.96187 , 37.25003 , 37.58104 , 37.890656,\n",
              "       38.13831 , 38.295124, 38.617935, 38.9512  , 39.00671 , 38.889492,\n",
              "       38.742996, 38.643833, 38.653183, 38.65415 , 38.685947, 38.705128,\n",
              "       38.74782 , 38.725754, 38.678062, 38.606297, 38.57553 , 38.583607,\n",
              "       38.594852, 38.585377, 38.46991 , 38.440136, 38.435776, 38.43658 ,\n",
              "       38.359882, 38.284946, 38.20513 , 38.203247, 38.23595 , 38.24401 ,\n",
              "       38.245655, 38.25166 , 38.365784, 38.50645 , 38.612232, 38.726845,\n",
              "       38.879307, 38.973625, 39.078144, 39.128407, 39.101215, 39.055935,\n",
              "       38.996628, 38.8869  , 38.76566 , 38.631676, 38.38922 , 38.048397,\n",
              "       37.761734, 37.55059 , 37.432434, 37.359276, 37.32655 , 37.33072 ,\n",
              "       37.31809 , 37.207092, 36.968277, 36.760586, 36.59714 , 36.50064 ,\n",
              "       36.400272, 36.43247 , 36.718575, 36.952972, 37.16245 , 37.470665,\n",
              "       37.67383 , 37.86061 , 38.064713, 38.168907, 38.19745 , 38.241383,\n",
              "       38.22723 , 38.182934, 38.292572, 38.629417, 39.05004 , 39.43951 ,\n",
              "       39.72944 , 39.904285, 39.980156, 40.002254, 39.91462 , 39.738907,\n",
              "       39.603245, 39.52393 , 39.495823, 39.527134, 39.56915 , 39.501514,\n",
              "       39.35993 , 38.966915, 38.566666, 38.207302, 37.912262, 37.660984,\n",
              "       37.399532, 37.2026  , 37.111187, 37.16314 , 37.23199 , 37.231815,\n",
              "       37.23929 , 37.21934 , 37.19073 , 37.150745, 37.091633, 37.18629 ,\n",
              "       37.422947, 37.641594, 37.61349 , 37.46244 , 37.135815, 36.804253,\n",
              "       36.118134, 35.500656, 35.162838, 34.90386 , 34.712234, 34.36311 ,\n",
              "       32.57315 , 30.778788, 29.269098, 27.70726 , 26.45241 , 25.449635,\n",
              "       24.66449 , 24.127108, 23.672464, 23.821516, 23.977488, 24.384542,\n",
              "       25.135073, 25.945942, 26.523157, 26.75523 , 27.0066  , 27.210611,\n",
              "       27.74723 , 28.673586, 30.012835, 30.993351, 31.641052, 32.01856 ,\n",
              "       32.221157, 32.36816 , 32.358692, 31.98298 , 31.626617, 31.434462,\n",
              "       31.201775, 30.86603 , 30.64802 , 30.540043, 30.489048, 30.38002 ,\n",
              "       30.355747, 30.569498, 30.792118, 30.903038, 31.066685, 31.281012,\n",
              "       31.55211 , 31.804745, 31.922506, 31.989885, 32.09695 , 32.26836 ,\n",
              "       32.438984, 32.62858 , 32.62089 , 32.599594, 32.659332, 32.678032,\n",
              "       32.567608, 32.389866, 32.302254, 32.364258, 32.653473, 33.162502,\n",
              "       33.925854, 34.395927, 34.703712, 34.791855, 34.58045 , 34.190254,\n",
              "       34.002815, 33.874336, 33.777504, 33.794746, 33.885674, 34.0468  ,\n",
              "       34.045906, 33.895813, 33.738155, 33.577164, 33.549614, 33.645786,\n",
              "       33.871315, 34.154327, 34.566914, 34.84116 , 34.99206 , 34.919327,\n",
              "       34.68024 , 34.42624 , 34.338238, 34.25502 , 34.257973, 34.274704,\n",
              "       34.524464, 34.741875, 34.930298, 34.92349 , 34.837166, 34.670166,\n",
              "       34.573277, 34.50154 , 34.386356, 34.377155, 34.403397, 34.35413 ,\n",
              "       34.239456, 34.079872, 34.01104 , 33.92337 , 33.879425, 33.86102 ,\n",
              "       33.767136, 33.50602 , 33.254932, 33.06705 , 33.019646, 32.996098,\n",
              "       33.034706, 33.020546, 32.88848 , 32.75169 , 32.66192 , 32.557426,\n",
              "       32.3204  , 32.05479 , 31.880644, 31.729248, 31.617716, 31.546286,\n",
              "       31.527418, 31.587845, 31.627455, 31.616016, 31.47495 , 31.217829,\n",
              "       30.7945  , 30.360746, 30.101557, 29.947481, 29.715935, 29.599205,\n",
              "       29.464874, 29.35956 , 29.382523, 29.442678, 29.547726, 29.676735,\n",
              "       29.917227, 30.062576, 30.10919 , 30.07303 , 29.96313 , 29.785933,\n",
              "       29.623598, 29.47987 , 29.362457, 29.252079, 29.114948, 28.888462,\n",
              "       28.669928, 28.48478 , 28.556477, 28.737053, 29.128546, 29.561113,\n",
              "       30.080313, 30.99925 , 31.957792, 32.650555, 33.146286, 33.52077 ,\n",
              "       33.744564, 33.905426, 34.011185, 34.117546, 34.504864, 34.92498 ,\n",
              "       35.457443, 36.02349 , 36.486217, 36.58253 , 36.649925, 36.666836,\n",
              "       36.82962 , 37.154125, 37.495644, 37.77426 , 37.886887, 37.946453,\n",
              "       37.97009 , 37.930763, 37.92694 , 37.61619 , 37.318874, 36.968018,\n",
              "       36.77172 , 36.76486 , 36.726543, 36.839764], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_copies_array = np.repeat(testY, 5, axis=-1)\n",
        "\n",
        "original_copies_array.shape\n",
        "\n",
        "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),5)))[:,-1]"
      ],
      "metadata": {
        "id": "Ja6k1OsABQyt"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHPJHolBQvT",
        "outputId": "8aea8fed-b658-47e5-8eda-3e8ad5e82e64"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([31.270653, 31.221369, 31.174221, 31.046467, 30.960163, 30.912539,\n",
              "       30.874022, 30.86937 , 30.924835, 30.994106, 31.092207, 31.145483,\n",
              "       31.161497, 31.166483, 31.15354 , 31.110355, 31.047981, 30.988   ,\n",
              "       30.918364, 30.852772, 30.823797, 30.804388, 30.79612 , 30.809462,\n",
              "       30.812983, 30.796919, 30.762083, 30.653374, 30.599167, 30.652521,\n",
              "       30.704819, 30.78178 , 30.870232, 30.953268, 31.023857, 31.099524,\n",
              "       31.156641, 31.175734, 31.193018, 31.1842  , 31.173073, 31.122318,\n",
              "       31.075665, 30.94317 , 30.805536, 30.70149 , 30.57862 , 30.478464,\n",
              "       30.389439, 30.355446, 30.35642 , 30.319324, 30.258823, 30.218952,\n",
              "       30.231462, 30.18761 , 30.134274, 30.112951, 30.102488, 30.10625 ,\n",
              "       30.08176 , 30.022991, 29.892414, 29.785164, 29.726152, 29.67557 ,\n",
              "       29.578764, 29.537477, 29.534832, 29.54328 , 29.596338, 29.641853,\n",
              "       29.699848, 29.795872, 29.908049, 29.987652, 30.034588, 30.053146,\n",
              "       30.131716, 30.283388, 30.437834, 30.5646  , 30.636236, 30.611492,\n",
              "       30.534119, 30.448988, 30.388645, 30.34867 , 30.341156, 30.33668 ,\n",
              "       30.314768, 30.330744, 30.358114, 30.39963 , 30.484064, 30.635347,\n",
              "       30.77799 , 30.918982, 31.027092, 31.108538, 31.174063, 31.284353,\n",
              "       31.43166 , 31.559998, 31.706722, 31.828245, 31.9399  , 32.01395 ,\n",
              "       32.149044, 32.299267, 32.404076, 32.50668 , 32.565804, 32.658295,\n",
              "       32.777756, 32.95354 , 33.154682, 33.299286, 33.370926, 33.28873 ,\n",
              "       33.206985, 33.239403, 33.294147, 33.314373, 33.2406  , 33.249866,\n",
              "       33.357708, 33.51973 , 33.605385, 33.6686  , 33.69084 , 33.79261 ,\n",
              "       33.961525, 34.04208 , 34.127342, 34.205696, 34.181824, 34.041016,\n",
              "       33.78508 , 33.53834 , 33.33355 , 33.243008, 33.27035 , 33.35026 ,\n",
              "       33.439243, 33.4556  , 33.44761 , 33.501247, 33.628296, 33.70107 ,\n",
              "       33.685802, 33.611725, 33.51708 , 33.471397, 33.37966 , 33.274445,\n",
              "       33.26231 , 33.27995 , 33.28454 , 33.29375 , 33.2754  , 33.254684,\n",
              "       33.268124, 33.273766, 33.253525, 33.22547 , 33.29222 , 33.399963,\n",
              "       33.523167, 33.617214, 33.695625, 33.84441 , 33.983387, 34.131573,\n",
              "       34.277405, 34.45661 , 34.655945, 34.84677 , 34.981285, 35.159542,\n",
              "       35.370182, 35.434963, 35.44369 , 35.382812, 35.321163, 35.383575,\n",
              "       35.75149 , 36.17859 , 36.535458, 36.80096 , 37.05016 , 37.218437,\n",
              "       37.340366, 37.595505, 37.833725, 38.012615, 38.119595, 38.12258 ,\n",
              "       38.165707, 38.275013, 38.426174, 38.51056 , 38.58103 , 38.757214,\n",
              "       38.827404, 38.865646, 38.97311 , 39.151688, 39.249466, 39.108658,\n",
              "       38.937405, 38.71378 , 38.477024, 38.38633 , 38.387703, 38.320423,\n",
              "       38.307014, 38.332447, 38.39942 , 38.480206, 38.990734, 39.77189 ,\n",
              "       40.52797 , 41.448082, 42.458317, 43.188187, 43.52039 , 43.72123 ,\n",
              "       43.809937, 43.67219 , 43.38551 , 43.076744, 43.163906, 43.460243,\n",
              "       43.734314, 43.945927, 43.955704, 43.74112 , 43.54696 , 43.407055,\n",
              "       43.32871 , 43.305363, 43.50559 , 43.75221 , 43.96472 , 43.95487 ,\n",
              "       43.926804, 43.902153, 43.794468, 43.50984 , 43.322044, 43.29345 ,\n",
              "       43.38377 , 43.41072 , 43.46509 , 43.48146 , 43.526894, 43.9321  ,\n",
              "       44.53683 , 44.899376, 45.21626 , 45.35941 , 45.320442, 45.19882 ,\n",
              "       45.071316, 44.97816 , 45.01826 , 45.001717, 44.98561 , 44.787426,\n",
              "       44.655678, 44.562523, 44.542377, 44.635265, 44.664062, 44.686325,\n",
              "       44.79119 , 44.883995, 44.957153, 44.76582 , 44.249912, 43.393475,\n",
              "       42.691895, 41.94595 , 41.43128 , 41.29151 , 41.173954, 41.137745,\n",
              "       41.165558, 41.314056, 41.450108, 41.4029  , 41.249947, 41.18792 ,\n",
              "       41.10888 , 41.00465 , 40.804962, 40.466343, 39.98189 , 39.650818,\n",
              "       39.256184, 38.988213, 38.828125, 38.691425, 38.63623 , 38.556557,\n",
              "       38.52873 , 38.500496, 38.46163 , 38.454304, 38.286087, 38.01643 ,\n",
              "       37.93372 , 38.098694, 38.347664, 38.538624, 38.62172 , 38.633385,\n",
              "       38.64378 , 38.87295 , 39.1514  , 39.622032, 40.081104, 40.357525,\n",
              "       40.584892, 40.850506, 41.014996, 41.252617, 41.435986, 41.535988,\n",
              "       41.554108, 41.609463, 41.77488 , 41.894535, 41.874493, 41.77932 ,\n",
              "       41.591064, 41.298836, 41.200073, 41.276287, 41.327805, 41.355164,\n",
              "       41.420593, 41.440895, 41.4875  , 41.604813, 41.707855, 41.746277,\n",
              "       41.792896, 41.886387, 41.924168, 41.682865, 41.366528, 41.021236,\n",
              "       40.75348 , 40.37884 , 40.10939 , 40.25428 , 40.520042, 40.67947 ,\n",
              "       40.89838 , 41.203995, 41.60765 , 42.011223, 42.36438 , 42.660923,\n",
              "       42.91219 , 43.03323 , 43.15013 , 43.29856 , 43.383442, 43.288216,\n",
              "       43.06388 , 42.771675, 42.416275, 42.144505, 42.176052, 41.951576,\n",
              "       41.813366, 41.66672 , 41.554646, 41.453644, 41.333405, 41.203575,\n",
              "       40.829876, 40.55442 , 40.247242, 40.0372  , 39.948566, 40.15931 ,\n",
              "       40.273884, 40.358818, 40.355957, 40.41019 , 40.52067 , 40.72912 ,\n",
              "       40.77599 , 40.775085, 40.76684 , 40.61264 , 40.41883 , 40.239372,\n",
              "       40.091515, 39.94824 , 39.793907, 39.64805 , 39.60489 , 39.586918,\n",
              "       39.615513, 39.710575, 39.85265 , 39.97393 , 40.392742, 40.81231 ,\n",
              "       40.994606, 40.991703, 40.857494, 40.666256, 40.259235, 39.87459 ,\n",
              "       39.605286, 39.39158 , 39.11835 , 38.877357, 38.764717, 38.745163,\n",
              "       38.45495 , 38.15628 , 37.9238  , 37.780483, 37.749954, 37.660343,\n",
              "       37.69759 , 37.999023, 38.347965, 38.706486, 39.041546, 39.401054,\n",
              "       39.52847 , 39.531387, 39.434395, 39.288185, 39.274258, 39.37604 ,\n",
              "       39.590942, 39.831604, 39.97781 , 40.00803 , 40.0044  , 39.885235,\n",
              "       39.764412, 39.721764, 39.808308, 39.93153 , 40.02117 , 40.04296 ,\n",
              "       40.061337, 40.00578 , 39.88879 , 39.80179 , 39.807064, 39.759777,\n",
              "       39.678635, 39.65309 , 39.69678 , 39.758293, 39.846603, 40.029224,\n",
              "       40.11135 , 40.168766, 40.120163, 40.048157, 39.9843  , 39.940937,\n",
              "       39.836258, 39.771614, 39.721386, 39.667587, 39.627796, 39.64015 ,\n",
              "       39.749252, 39.895245, 39.973354, 40.10621 , 40.21834 , 40.308956,\n",
              "       40.441982, 40.407234, 40.36017 , 40.24539 , 40.11749 , 40.08448 ,\n",
              "       40.105816, 40.13765 , 40.18724 , 40.208565, 40.18458 , 40.183506,\n",
              "       40.22553 , 40.273895, 40.290997, 40.34936 , 40.44618 , 40.518555,\n",
              "       40.658424, 40.850105, 41.032486, 41.156776, 41.21199 , 41.16038 ,\n",
              "       41.076946, 41.025192, 41.016403, 40.951595, 40.795464, 40.565704,\n",
              "       40.373062, 40.18803 , 40.001038, 39.86252 , 39.723274, 39.545345,\n",
              "       39.341557, 39.19611 , 39.0006  , 38.796383, 38.733246, 38.83183 ,\n",
              "       38.914265, 38.94727 , 38.952206, 38.96264 , 39.07255 , 39.185516,\n",
              "       39.28764 , 39.406082, 39.53784 , 39.586887, 39.579277, 39.504868,\n",
              "       39.416855, 39.441376, 39.60387 , 39.869495, 40.178894, 40.449352,\n",
              "       40.620342, 40.698257, 40.761272, 40.80646 , 40.93061 , 40.922894,\n",
              "       40.824173, 40.717377, 40.61455 , 40.52849 , 40.40613 , 40.350796,\n",
              "       40.344635, 40.281086, 40.200626, 40.154152, 40.100945, 40.063614,\n",
              "       40.03434 , 40.021774, 40.006367, 40.005753, 39.937057, 39.860462,\n",
              "       39.791283, 39.72803 , 39.51271 , 39.259888, 38.977158, 38.68101 ,\n",
              "       38.309784, 37.973988, 37.524536, 37.1628  , 36.738876, 36.44028 ,\n",
              "       36.314247, 36.21959 , 36.194977, 36.093647, 36.034912, 35.79157 ,\n",
              "       35.498104, 35.25221 , 35.324745, 35.70814 , 36.056637, 36.24111 ,\n",
              "       36.41721 , 36.684765, 36.96187 , 37.25003 , 37.58104 , 37.890656,\n",
              "       38.13831 , 38.295124, 38.617935, 38.9512  , 39.00671 , 38.889492,\n",
              "       38.742996, 38.643833, 38.653183, 38.65415 , 38.685947, 38.705128,\n",
              "       38.74782 , 38.725754, 38.678062, 38.606297, 38.57553 , 38.583607,\n",
              "       38.594852, 38.585377, 38.46991 , 38.440136, 38.435776, 38.43658 ,\n",
              "       38.359882, 38.284946, 38.20513 , 38.203247, 38.23595 , 38.24401 ,\n",
              "       38.245655, 38.25166 , 38.365784, 38.50645 , 38.612232, 38.726845,\n",
              "       38.879307, 38.973625, 39.078144, 39.128407, 39.101215, 39.055935,\n",
              "       38.996628, 38.8869  , 38.76566 , 38.631676, 38.38922 , 38.048397,\n",
              "       37.761734, 37.55059 , 37.432434, 37.359276, 37.32655 , 37.33072 ,\n",
              "       37.31809 , 37.207092, 36.968277, 36.760586, 36.59714 , 36.50064 ,\n",
              "       36.400272, 36.43247 , 36.718575, 36.952972, 37.16245 , 37.470665,\n",
              "       37.67383 , 37.86061 , 38.064713, 38.168907, 38.19745 , 38.241383,\n",
              "       38.22723 , 38.182934, 38.292572, 38.629417, 39.05004 , 39.43951 ,\n",
              "       39.72944 , 39.904285, 39.980156, 40.002254, 39.91462 , 39.738907,\n",
              "       39.603245, 39.52393 , 39.495823, 39.527134, 39.56915 , 39.501514,\n",
              "       39.35993 , 38.966915, 38.566666, 38.207302, 37.912262, 37.660984,\n",
              "       37.399532, 37.2026  , 37.111187, 37.16314 , 37.23199 , 37.231815,\n",
              "       37.23929 , 37.21934 , 37.19073 , 37.150745, 37.091633, 37.18629 ,\n",
              "       37.422947, 37.641594, 37.61349 , 37.46244 , 37.135815, 36.804253,\n",
              "       36.118134, 35.500656, 35.162838, 34.90386 , 34.712234, 34.36311 ,\n",
              "       32.57315 , 30.778788, 29.269098, 27.70726 , 26.45241 , 25.449635,\n",
              "       24.66449 , 24.127108, 23.672464, 23.821516, 23.977488, 24.384542,\n",
              "       25.135073, 25.945942, 26.523157, 26.75523 , 27.0066  , 27.210611,\n",
              "       27.74723 , 28.673586, 30.012835, 30.993351, 31.641052, 32.01856 ,\n",
              "       32.221157, 32.36816 , 32.358692, 31.98298 , 31.626617, 31.434462,\n",
              "       31.201775, 30.86603 , 30.64802 , 30.540043, 30.489048, 30.38002 ,\n",
              "       30.355747, 30.569498, 30.792118, 30.903038, 31.066685, 31.281012,\n",
              "       31.55211 , 31.804745, 31.922506, 31.989885, 32.09695 , 32.26836 ,\n",
              "       32.438984, 32.62858 , 32.62089 , 32.599594, 32.659332, 32.678032,\n",
              "       32.567608, 32.389866, 32.302254, 32.364258, 32.653473, 33.162502,\n",
              "       33.925854, 34.395927, 34.703712, 34.791855, 34.58045 , 34.190254,\n",
              "       34.002815, 33.874336, 33.777504, 33.794746, 33.885674, 34.0468  ,\n",
              "       34.045906, 33.895813, 33.738155, 33.577164, 33.549614, 33.645786,\n",
              "       33.871315, 34.154327, 34.566914, 34.84116 , 34.99206 , 34.919327,\n",
              "       34.68024 , 34.42624 , 34.338238, 34.25502 , 34.257973, 34.274704,\n",
              "       34.524464, 34.741875, 34.930298, 34.92349 , 34.837166, 34.670166,\n",
              "       34.573277, 34.50154 , 34.386356, 34.377155, 34.403397, 34.35413 ,\n",
              "       34.239456, 34.079872, 34.01104 , 33.92337 , 33.879425, 33.86102 ,\n",
              "       33.767136, 33.50602 , 33.254932, 33.06705 , 33.019646, 32.996098,\n",
              "       33.034706, 33.020546, 32.88848 , 32.75169 , 32.66192 , 32.557426,\n",
              "       32.3204  , 32.05479 , 31.880644, 31.729248, 31.617716, 31.546286,\n",
              "       31.527418, 31.587845, 31.627455, 31.616016, 31.47495 , 31.217829,\n",
              "       30.7945  , 30.360746, 30.101557, 29.947481, 29.715935, 29.599205,\n",
              "       29.464874, 29.35956 , 29.382523, 29.442678, 29.547726, 29.676735,\n",
              "       29.917227, 30.062576, 30.10919 , 30.07303 , 29.96313 , 29.785933,\n",
              "       29.623598, 29.47987 , 29.362457, 29.252079, 29.114948, 28.888462,\n",
              "       28.669928, 28.48478 , 28.556477, 28.737053, 29.128546, 29.561113,\n",
              "       30.080313, 30.99925 , 31.957792, 32.650555, 33.146286, 33.52077 ,\n",
              "       33.744564, 33.905426, 34.011185, 34.117546, 34.504864, 34.92498 ,\n",
              "       35.457443, 36.02349 , 36.486217, 36.58253 , 36.649925, 36.666836,\n",
              "       36.82962 , 37.154125, 37.495644, 37.77426 , 37.886887, 37.946453,\n",
              "       37.97009 , 37.930763, 37.92694 , 37.61619 , 37.318874, 36.968018,\n",
              "       36.77172 , 36.76486 , 36.726543, 36.839764], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pred Values-- \" ,pred)\n",
        "print(\"\\nOriginal Values-- \",original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2eOXDgBWs9",
        "outputId": "50085f4b-9413-4e8d-82e2-5f644c6a62f6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred Values--  [31.270653 31.221369 31.174221 31.046467 30.960163 30.912539 30.874022\n",
            " 30.86937  30.924835 30.994106 31.092207 31.145483 31.161497 31.166483\n",
            " 31.15354  31.110355 31.047981 30.988    30.918364 30.852772 30.823797\n",
            " 30.804388 30.79612  30.809462 30.812983 30.796919 30.762083 30.653374\n",
            " 30.599167 30.652521 30.704819 30.78178  30.870232 30.953268 31.023857\n",
            " 31.099524 31.156641 31.175734 31.193018 31.1842   31.173073 31.122318\n",
            " 31.075665 30.94317  30.805536 30.70149  30.57862  30.478464 30.389439\n",
            " 30.355446 30.35642  30.319324 30.258823 30.218952 30.231462 30.18761\n",
            " 30.134274 30.112951 30.102488 30.10625  30.08176  30.022991 29.892414\n",
            " 29.785164 29.726152 29.67557  29.578764 29.537477 29.534832 29.54328\n",
            " 29.596338 29.641853 29.699848 29.795872 29.908049 29.987652 30.034588\n",
            " 30.053146 30.131716 30.283388 30.437834 30.5646   30.636236 30.611492\n",
            " 30.534119 30.448988 30.388645 30.34867  30.341156 30.33668  30.314768\n",
            " 30.330744 30.358114 30.39963  30.484064 30.635347 30.77799  30.918982\n",
            " 31.027092 31.108538 31.174063 31.284353 31.43166  31.559998 31.706722\n",
            " 31.828245 31.9399   32.01395  32.149044 32.299267 32.404076 32.50668\n",
            " 32.565804 32.658295 32.777756 32.95354  33.154682 33.299286 33.370926\n",
            " 33.28873  33.206985 33.239403 33.294147 33.314373 33.2406   33.249866\n",
            " 33.357708 33.51973  33.605385 33.6686   33.69084  33.79261  33.961525\n",
            " 34.04208  34.127342 34.205696 34.181824 34.041016 33.78508  33.53834\n",
            " 33.33355  33.243008 33.27035  33.35026  33.439243 33.4556   33.44761\n",
            " 33.501247 33.628296 33.70107  33.685802 33.611725 33.51708  33.471397\n",
            " 33.37966  33.274445 33.26231  33.27995  33.28454  33.29375  33.2754\n",
            " 33.254684 33.268124 33.273766 33.253525 33.22547  33.29222  33.399963\n",
            " 33.523167 33.617214 33.695625 33.84441  33.983387 34.131573 34.277405\n",
            " 34.45661  34.655945 34.84677  34.981285 35.159542 35.370182 35.434963\n",
            " 35.44369  35.382812 35.321163 35.383575 35.75149  36.17859  36.535458\n",
            " 36.80096  37.05016  37.218437 37.340366 37.595505 37.833725 38.012615\n",
            " 38.119595 38.12258  38.165707 38.275013 38.426174 38.51056  38.58103\n",
            " 38.757214 38.827404 38.865646 38.97311  39.151688 39.249466 39.108658\n",
            " 38.937405 38.71378  38.477024 38.38633  38.387703 38.320423 38.307014\n",
            " 38.332447 38.39942  38.480206 38.990734 39.77189  40.52797  41.448082\n",
            " 42.458317 43.188187 43.52039  43.72123  43.809937 43.67219  43.38551\n",
            " 43.076744 43.163906 43.460243 43.734314 43.945927 43.955704 43.74112\n",
            " 43.54696  43.407055 43.32871  43.305363 43.50559  43.75221  43.96472\n",
            " 43.95487  43.926804 43.902153 43.794468 43.50984  43.322044 43.29345\n",
            " 43.38377  43.41072  43.46509  43.48146  43.526894 43.9321   44.53683\n",
            " 44.899376 45.21626  45.35941  45.320442 45.19882  45.071316 44.97816\n",
            " 45.01826  45.001717 44.98561  44.787426 44.655678 44.562523 44.542377\n",
            " 44.635265 44.664062 44.686325 44.79119  44.883995 44.957153 44.76582\n",
            " 44.249912 43.393475 42.691895 41.94595  41.43128  41.29151  41.173954\n",
            " 41.137745 41.165558 41.314056 41.450108 41.4029   41.249947 41.18792\n",
            " 41.10888  41.00465  40.804962 40.466343 39.98189  39.650818 39.256184\n",
            " 38.988213 38.828125 38.691425 38.63623  38.556557 38.52873  38.500496\n",
            " 38.46163  38.454304 38.286087 38.01643  37.93372  38.098694 38.347664\n",
            " 38.538624 38.62172  38.633385 38.64378  38.87295  39.1514   39.622032\n",
            " 40.081104 40.357525 40.584892 40.850506 41.014996 41.252617 41.435986\n",
            " 41.535988 41.554108 41.609463 41.77488  41.894535 41.874493 41.77932\n",
            " 41.591064 41.298836 41.200073 41.276287 41.327805 41.355164 41.420593\n",
            " 41.440895 41.4875   41.604813 41.707855 41.746277 41.792896 41.886387\n",
            " 41.924168 41.682865 41.366528 41.021236 40.75348  40.37884  40.10939\n",
            " 40.25428  40.520042 40.67947  40.89838  41.203995 41.60765  42.011223\n",
            " 42.36438  42.660923 42.91219  43.03323  43.15013  43.29856  43.383442\n",
            " 43.288216 43.06388  42.771675 42.416275 42.144505 42.176052 41.951576\n",
            " 41.813366 41.66672  41.554646 41.453644 41.333405 41.203575 40.829876\n",
            " 40.55442  40.247242 40.0372   39.948566 40.15931  40.273884 40.358818\n",
            " 40.355957 40.41019  40.52067  40.72912  40.77599  40.775085 40.76684\n",
            " 40.61264  40.41883  40.239372 40.091515 39.94824  39.793907 39.64805\n",
            " 39.60489  39.586918 39.615513 39.710575 39.85265  39.97393  40.392742\n",
            " 40.81231  40.994606 40.991703 40.857494 40.666256 40.259235 39.87459\n",
            " 39.605286 39.39158  39.11835  38.877357 38.764717 38.745163 38.45495\n",
            " 38.15628  37.9238   37.780483 37.749954 37.660343 37.69759  37.999023\n",
            " 38.347965 38.706486 39.041546 39.401054 39.52847  39.531387 39.434395\n",
            " 39.288185 39.274258 39.37604  39.590942 39.831604 39.97781  40.00803\n",
            " 40.0044   39.885235 39.764412 39.721764 39.808308 39.93153  40.02117\n",
            " 40.04296  40.061337 40.00578  39.88879  39.80179  39.807064 39.759777\n",
            " 39.678635 39.65309  39.69678  39.758293 39.846603 40.029224 40.11135\n",
            " 40.168766 40.120163 40.048157 39.9843   39.940937 39.836258 39.771614\n",
            " 39.721386 39.667587 39.627796 39.64015  39.749252 39.895245 39.973354\n",
            " 40.10621  40.21834  40.308956 40.441982 40.407234 40.36017  40.24539\n",
            " 40.11749  40.08448  40.105816 40.13765  40.18724  40.208565 40.18458\n",
            " 40.183506 40.22553  40.273895 40.290997 40.34936  40.44618  40.518555\n",
            " 40.658424 40.850105 41.032486 41.156776 41.21199  41.16038  41.076946\n",
            " 41.025192 41.016403 40.951595 40.795464 40.565704 40.373062 40.18803\n",
            " 40.001038 39.86252  39.723274 39.545345 39.341557 39.19611  39.0006\n",
            " 38.796383 38.733246 38.83183  38.914265 38.94727  38.952206 38.96264\n",
            " 39.07255  39.185516 39.28764  39.406082 39.53784  39.586887 39.579277\n",
            " 39.504868 39.416855 39.441376 39.60387  39.869495 40.178894 40.449352\n",
            " 40.620342 40.698257 40.761272 40.80646  40.93061  40.922894 40.824173\n",
            " 40.717377 40.61455  40.52849  40.40613  40.350796 40.344635 40.281086\n",
            " 40.200626 40.154152 40.100945 40.063614 40.03434  40.021774 40.006367\n",
            " 40.005753 39.937057 39.860462 39.791283 39.72803  39.51271  39.259888\n",
            " 38.977158 38.68101  38.309784 37.973988 37.524536 37.1628   36.738876\n",
            " 36.44028  36.314247 36.21959  36.194977 36.093647 36.034912 35.79157\n",
            " 35.498104 35.25221  35.324745 35.70814  36.056637 36.24111  36.41721\n",
            " 36.684765 36.96187  37.25003  37.58104  37.890656 38.13831  38.295124\n",
            " 38.617935 38.9512   39.00671  38.889492 38.742996 38.643833 38.653183\n",
            " 38.65415  38.685947 38.705128 38.74782  38.725754 38.678062 38.606297\n",
            " 38.57553  38.583607 38.594852 38.585377 38.46991  38.440136 38.435776\n",
            " 38.43658  38.359882 38.284946 38.20513  38.203247 38.23595  38.24401\n",
            " 38.245655 38.25166  38.365784 38.50645  38.612232 38.726845 38.879307\n",
            " 38.973625 39.078144 39.128407 39.101215 39.055935 38.996628 38.8869\n",
            " 38.76566  38.631676 38.38922  38.048397 37.761734 37.55059  37.432434\n",
            " 37.359276 37.32655  37.33072  37.31809  37.207092 36.968277 36.760586\n",
            " 36.59714  36.50064  36.400272 36.43247  36.718575 36.952972 37.16245\n",
            " 37.470665 37.67383  37.86061  38.064713 38.168907 38.19745  38.241383\n",
            " 38.22723  38.182934 38.292572 38.629417 39.05004  39.43951  39.72944\n",
            " 39.904285 39.980156 40.002254 39.91462  39.738907 39.603245 39.52393\n",
            " 39.495823 39.527134 39.56915  39.501514 39.35993  38.966915 38.566666\n",
            " 38.207302 37.912262 37.660984 37.399532 37.2026   37.111187 37.16314\n",
            " 37.23199  37.231815 37.23929  37.21934  37.19073  37.150745 37.091633\n",
            " 37.18629  37.422947 37.641594 37.61349  37.46244  37.135815 36.804253\n",
            " 36.118134 35.500656 35.162838 34.90386  34.712234 34.36311  32.57315\n",
            " 30.778788 29.269098 27.70726  26.45241  25.449635 24.66449  24.127108\n",
            " 23.672464 23.821516 23.977488 24.384542 25.135073 25.945942 26.523157\n",
            " 26.75523  27.0066   27.210611 27.74723  28.673586 30.012835 30.993351\n",
            " 31.641052 32.01856  32.221157 32.36816  32.358692 31.98298  31.626617\n",
            " 31.434462 31.201775 30.86603  30.64802  30.540043 30.489048 30.38002\n",
            " 30.355747 30.569498 30.792118 30.903038 31.066685 31.281012 31.55211\n",
            " 31.804745 31.922506 31.989885 32.09695  32.26836  32.438984 32.62858\n",
            " 32.62089  32.599594 32.659332 32.678032 32.567608 32.389866 32.302254\n",
            " 32.364258 32.653473 33.162502 33.925854 34.395927 34.703712 34.791855\n",
            " 34.58045  34.190254 34.002815 33.874336 33.777504 33.794746 33.885674\n",
            " 34.0468   34.045906 33.895813 33.738155 33.577164 33.549614 33.645786\n",
            " 33.871315 34.154327 34.566914 34.84116  34.99206  34.919327 34.68024\n",
            " 34.42624  34.338238 34.25502  34.257973 34.274704 34.524464 34.741875\n",
            " 34.930298 34.92349  34.837166 34.670166 34.573277 34.50154  34.386356\n",
            " 34.377155 34.403397 34.35413  34.239456 34.079872 34.01104  33.92337\n",
            " 33.879425 33.86102  33.767136 33.50602  33.254932 33.06705  33.019646\n",
            " 32.996098 33.034706 33.020546 32.88848  32.75169  32.66192  32.557426\n",
            " 32.3204   32.05479  31.880644 31.729248 31.617716 31.546286 31.527418\n",
            " 31.587845 31.627455 31.616016 31.47495  31.217829 30.7945   30.360746\n",
            " 30.101557 29.947481 29.715935 29.599205 29.464874 29.35956  29.382523\n",
            " 29.442678 29.547726 29.676735 29.917227 30.062576 30.10919  30.07303\n",
            " 29.96313  29.785933 29.623598 29.47987  29.362457 29.252079 29.114948\n",
            " 28.888462 28.669928 28.48478  28.556477 28.737053 29.128546 29.561113\n",
            " 30.080313 30.99925  31.957792 32.650555 33.146286 33.52077  33.744564\n",
            " 33.905426 34.011185 34.117546 34.504864 34.92498  35.457443 36.02349\n",
            " 36.486217 36.58253  36.649925 36.666836 36.82962  37.154125 37.495644\n",
            " 37.77426  37.886887 37.946453 37.97009  37.930763 37.92694  37.61619\n",
            " 37.318874 36.968018 36.77172  36.76486  36.726543 36.839764]\n",
            "\n",
            "Original Values--  [32.84584808 32.84584808 32.18061447 32.59638596 32.59638596 32.4300766\n",
            " 32.59638596 32.84584808 32.76270294 33.01216125 32.67954254 32.59638596\n",
            " 32.67954254 32.59638596 32.4300766  32.34693146 32.4300766  32.26376343\n",
            " 32.26376343 32.34693146 32.34693146 32.34693146 32.4300766  32.34693146\n",
            " 32.18061447 32.0974617  31.68169212 32.0974617  32.67954254 32.34693146\n",
            " 32.59638596 32.67954254 32.67954254 32.67954254 32.84584808 32.76270294\n",
            " 32.67954254 32.76270294 32.59638596 32.67954254 32.4300766  32.51322556\n",
            " 31.84799385 32.01430511 32.01430511 31.7648468  31.84799385 31.68169212\n",
            " 32.01430511 31.93115616 31.59853745 31.51538467 31.59853745 31.93115616\n",
            " 31.3490715  31.43223381 31.59853745 31.51538467 31.59853745 31.3490715\n",
            " 31.18276978 30.76699638 31.01645851 31.09960938 31.01645851 30.68384361\n",
            " 31.09960938 31.01645851 30.93330383 31.26592445 31.09960938 31.26592445\n",
            " 31.59853745 31.59853745 31.43223381 31.43223381 31.43223381 32.01430511\n",
            " 32.26376343 32.26376343 32.26376343 32.0974617  31.68169212 31.59853745\n",
            " 31.68169212 31.7648468  31.7648468  31.93115616 31.7648468  31.68169212\n",
            " 31.93115616 31.93115616 32.01430511 32.34693146 32.67954254 32.59638596\n",
            " 32.76270294 32.67954254 32.76270294 32.76270294 33.26162338 33.42792892\n",
            " 33.8521347  33.93698502 33.8521347  33.93698502 33.76729584 34.44603348\n",
            " 34.44603348 34.27635193 34.44603348 34.27635193 34.78540039 34.95508957\n",
            " 35.29446411 35.63383102 35.29446411 35.12477493 34.44603348 34.95508957\n",
            " 35.46414566 35.46414566 35.12477493 34.61572266 35.46414566 35.80351639\n",
            " 35.97320557 35.46414566 35.63383102 35.46414566 36.31256485 36.48225403\n",
            " 35.97320557 36.31256485 36.48225403 35.80351639 35.29446411 34.78540039\n",
            " 34.78540039 34.78540039 35.29446411 35.63383102 35.63383102 35.63383102\n",
            " 35.29446411 35.29446411 35.80351639 35.97320557 35.63383102 35.29446411\n",
            " 35.12477493 35.12477493 35.46414566 34.95508957 34.78540039 35.46414566\n",
            " 35.29446411 35.12477493 35.12477493 34.95508957 35.12477493 35.29446411\n",
            " 35.12477493 34.95508957 34.95508957 35.63383102 35.63383102 35.80351639\n",
            " 35.63383102 35.80351639 36.31256485 36.1428833  36.48225403 36.65193939\n",
            " 36.9913063  37.16099167 37.33068466 37.16099167 37.83973312 38.0094223\n",
            " 37.33068466 37.33068466 37.16099167 37.33068466 38.17910004 40.04564285\n",
            " 39.70626831 39.53657913 39.53657913 39.87595367 40.04564285 39.87595367\n",
            " 41.06375122 40.89406204 41.06375122 40.72437668 40.55469131 41.06375122\n",
            " 41.40311432 41.74248886 41.23343277 41.5728035  42.25153732 41.5728035\n",
            " 41.74248886 42.25153732 42.59091187 42.42122269 41.06375122 41.06375122\n",
            " 40.72437668 40.72437668 41.40311432 41.40311432 40.72437668 41.23343277\n",
            " 41.23343277 41.40311432 41.5728035  44.28775787 45.81492615 45.64524078\n",
            " 48.02082825 48.6995697  48.19051361 47.17240143 47.68146133 47.85484314\n",
            " 46.81452179 46.12097168 46.29436111 48.375      49.06855392 48.54839706\n",
            " 48.375      47.5080719  46.46775055 46.98791122 46.98791122 47.16129684\n",
            " 47.68146133 48.54839706 48.54839706 48.54839706 47.5080719  47.85484314\n",
            " 47.85484314 47.33468246 46.12097168 46.98791122 47.68146133 47.85484314\n",
            " 47.33468246 47.68146133 47.33468246 47.68146133 50.28226471 50.97581482\n",
            " 49.58871841 50.28226471 49.84880066 48.9818573  48.9818573  48.9818573\n",
            " 49.41532898 49.84880066 49.19859695 49.19859695 48.11492157 48.76512527\n",
            " 48.54839706 49.19859695 49.41532898 48.9818573  48.9818573  49.63206482\n",
            " 49.41532898 49.41532898 47.89818954 46.38105392 43.99698257 45.08064651\n",
            " 43.56351471 44.64718246 45.29737854 44.64718246 44.86391449 45.08064651\n",
            " 45.51411438 45.29737854 44.21371841 43.99698257 44.64718246 44.21371841\n",
            " 44.21371841 43.34678268 42.47984695 41.39617538 42.26311111 41.17944336\n",
            " 41.61290741 41.61290741 41.61290741 41.61290741 41.17944336 41.61290741\n",
            " 41.39617538 41.17944336 41.39617538 40.09577179 40.09577179 40.74597549\n",
            " 42.26311111 42.04637909 41.61290741 41.17944336 41.17944336 41.39617538\n",
            " 42.91331482 42.91331482 44.64718246 44.21371841 43.56351471 44.21371841\n",
            " 44.86391449 44.43044662 45.51411438 45.08064651 44.86391449 44.64718246\n",
            " 45.29737854 45.94758606 45.51411438 44.86391449 44.86391449 44.21371841\n",
            " 43.78024673 44.64718246 45.29737854 44.86391449 44.86391449 45.08064651\n",
            " 44.86391449 45.08064651 45.51411438 45.51411438 45.08064651 45.51411438\n",
            " 45.73085022 45.29737854 43.78024673 43.78024673 43.34678268 43.56351471\n",
            " 42.26311111 42.91331482 45.08064651 44.86391449 44.21371841 45.08064651\n",
            " 45.51411438 46.38105392 46.59778595 46.81452179 46.81452179 47.03125381\n",
            " 46.81452179 47.03125381 47.46472168 47.24798965 46.38105392 45.94758606\n",
            " 45.51411438 44.86391449 45.29737854 46.81452179 44.87858582 45.31856918\n",
            " 44.87858582 44.87858582 44.87858582 44.43859863 44.21860504 42.67865372\n",
            " 43.55862427 42.45865631 42.89864349 43.33863068 44.87858582 43.55862427\n",
            " 43.77861786 43.33863068 43.77861786 44.21860504 44.65859222 43.77861786\n",
            " 43.77861786 43.99861145 43.11863708 42.89864349 42.89864349 42.89864349\n",
            " 42.67865372 42.45865631 42.23866272 42.89864349 42.67865372 42.89864349\n",
            " 43.11863708 43.33863068 43.33863068 45.53855896 45.31856918 44.21860504\n",
            " 43.55862427 43.33863068 43.11863708 41.79868317 42.01867294 42.23866272\n",
            " 42.23866272 41.35869217 41.13870239 41.79868317 41.79868317 39.81874466\n",
            " 40.03873444 40.03873444 40.47872162 40.69871521 40.03873444 41.13870239\n",
            " 42.23866272 42.23866272 42.45865631 42.89864349 43.33863068 42.23866272\n",
            " 42.01867294 41.79868317 41.57868576 42.45865631 42.89864349 43.55862427\n",
            " 43.55862427 43.11863708 42.89864349 42.89864349 42.45865631 42.45865631\n",
            " 42.67865372 43.55862427 43.33863068 43.33863068 42.89864349 43.11863708\n",
            " 42.67865372 42.45865631 42.67865372 43.11863708 42.45865631 42.45865631\n",
            " 42.67865372 43.11863708 42.89864349 43.33863068 43.77861786 43.11863708\n",
            " 43.33863068 42.67865372 42.89864349 42.89864349 42.89864349 42.85353851\n",
            " 43.07908249 42.85353851 42.62799072 42.62799072 43.07908249 43.30462646\n",
            " 43.53017044 43.07908249 43.75571442 43.53017044 43.53017044 43.98125839\n",
            " 43.07908249 43.30462646 42.85353851 42.85353851 43.30462646 43.30462646\n",
            " 43.30462646 43.53017044 43.30462646 43.07908249 43.30462646 43.53017044\n",
            " 43.53017044 43.30462646 43.75571442 43.98125839 43.75571442 44.43235397\n",
            " 44.65789795 44.65789795 44.65789795 44.43235397 43.98125839 43.98125839\n",
            " 44.20680618 44.43235397 43.98125839 43.30462646 42.85353851 43.07908249\n",
            " 42.85353851 42.62799072 42.62799072 42.40244675 41.9513588  41.72581482\n",
            " 41.9513588  41.27472305 41.27472305 41.72581482 42.62799072 41.9513588\n",
            " 41.72581482 41.72581482 41.9513588  42.40244675 42.40244675 42.40244675\n",
            " 42.62799072 42.85353851 42.40244675 42.40244675 41.9513588  41.9513588\n",
            " 42.85353851 43.30462646 43.98125839 44.20680618 44.20680618 43.98125839\n",
            " 43.75571442 43.98125839 43.98125839 44.65789795 43.75571442 43.53017044\n",
            " 43.53017044 43.53017044 43.53017044 43.07908249 43.53017044 43.53017044\n",
            " 43.07908249 43.07908249 43.30462646 43.07908249 43.07908249 43.07908249\n",
            " 43.07908249 43.07908249 43.07908249 42.62799072 42.62799072 42.62799072\n",
            " 42.62799072 41.50026321 41.27472305 41.04917908 40.59808731 39.92145538\n",
            " 39.92145538 38.79372787 39.01927185 38.11709213 38.5681839  39.01927185\n",
            " 38.5681839  38.79372787 38.11709213 38.34263611 36.98936844 36.76382828\n",
            " 36.98936844 39.01927185 39.92145538 39.24481964 38.5681839  39.24481964\n",
            " 39.92145538 40.14699554 40.59808731 41.04917908 41.27472305 41.04917908\n",
            " 41.04917908 42.40244675 42.62799072 41.27472305 40.82363129 41.04917908\n",
            " 41.27472305 41.72581482 41.50026321 41.50026321 41.50026321 41.72581482\n",
            " 41.27472305 41.27472305 41.04917908 41.27472305 41.50026321 41.27472305\n",
            " 41.27472305 40.95262146 41.64283752 41.4127655  41.4127655  40.72255707\n",
            " 40.95262146 40.72255707 41.1826973  41.1826973  40.95262146 40.95262146\n",
            " 40.95262146 41.87290955 41.64283752 41.64283752 41.87290955 42.10297394\n",
            " 41.87290955 42.33304977 41.87290955 41.64283752 41.64283752 41.64283752\n",
            " 41.1826973  41.1826973  40.95262146 40.26241302 39.57219696 39.80226898\n",
            " 39.80226898 40.032341   39.80226898 40.032341   40.032341   39.80226898\n",
            " 39.11205673 38.42184448 38.88198471 38.6519165  38.88198471 38.6519165\n",
            " 39.34212875 40.49248123 40.032341   40.26241302 41.1826973  40.72255707\n",
            " 40.95262146 41.1826973  40.72255707 40.72255707 40.95262146 40.72255707\n",
            " 40.49248123 41.87290955 42.79319382 43.25333405 43.48340607 43.02326202\n",
            " 43.25333405 42.79319382 42.79319382 42.33304977 41.87290955 42.33304977\n",
            " 42.33304977 42.5631218  42.79319382 42.5631218  42.10297394 41.64283752\n",
            " 40.032341   40.26241302 40.032341   40.032341   39.80226898 39.34212875\n",
            " 39.57219696 39.80226898 40.26241302 40.032341   39.57219696 39.80226898\n",
            " 39.57219696 39.57219696 39.57219696 39.34212875 40.49248123 41.1826973\n",
            " 40.95262146 39.34212875 39.11205673 38.19177246 38.42184448 35.89106369\n",
            " 36.12113953 37.50156021 37.35968781 36.88677979 35.46805954 26.4828167\n",
            " 26.95572472 27.66508484 25.06409645 26.4828167  24.82764053 24.59118652\n",
            " 25.06409645 24.35473251 27.90153885 25.77345657 27.42863083 29.55671501\n",
            " 29.55671501 28.37444687 27.42863083 29.0838089  28.61089897 31.9212532\n",
            " 33.57642746 36.17741776 34.04933929 33.81288147 34.04933929 33.81288147\n",
            " 34.04933929 33.57642746 31.44834328 32.39415741 33.33997726 32.15770721\n",
            " 31.44834328 31.9212532  32.15770721 32.15770721 31.68479919 32.15770721\n",
            " 33.57642746 33.10351944 32.39415741 33.33997726 33.57642746 34.28578949\n",
            " 34.04933929 33.57642746 33.57642746 34.04933929 34.5222435  34.75869751\n",
            " 34.99514771 33.81288147 34.28578949 34.75869751 34.5222435  33.57642746\n",
            " 33.57642746 34.04933929 34.99514771 35.94096756 37.35968781 38.54195404\n",
            " 36.88677979 37.1232338  36.41387177 35.23160553 34.5222435  35.94096756\n",
            " 35.94096756 35.70451355 36.17741776 36.41387177 36.65032959 35.46805954\n",
            " 35.23160553 34.99514771 35.23160553 35.70451355 36.41387177 36.88677979\n",
            " 37.1232338  38.06904984 37.35968781 37.1232338  36.17741776 35.46805954\n",
            " 35.94096756 36.65032959 36.17741776 36.65032959 36.41387177 38.06904984\n",
            " 37.35968781 37.59614182 36.41387177 36.41387177 35.94096756 36.88677979\n",
            " 36.41387177 35.94096756 36.88677979 36.65032959 36.17741776 35.70451355\n",
            " 35.46805954 36.17741776 35.70451355 35.94096756 35.94096756 35.23160553\n",
            " 34.28578949 34.5222435  34.75869751 35.23160553 34.99514771 35.23160553\n",
            " 34.75869751 34.04933929 34.28578949 34.5222435  34.04933929 33.10351944\n",
            " 33.33997726 33.33997726 33.10351944 33.10351944 33.33997726 33.33997726\n",
            " 33.81288147 33.33997726 33.10351944 32.39415741 31.68479919 30.73898506\n",
            " 30.73898506 31.68479919 31.44834328 30.43081474 31.38177681 30.66855431\n",
            " 30.66855431 31.38177681 31.38177681 31.38177681 31.61951637 32.57048035\n",
            " 31.61951637 31.38177681 31.14403725 30.90629768 30.66855431 30.66855431\n",
            " 30.66855431 30.66855431 30.43081474 29.95533371 29.47985077 29.47985077\n",
            " 29.47985077 31.14403725 30.90629768 32.33274078 32.33274078 33.04596329\n",
            " 36.37433243 36.37433243 35.42337036 35.66111374 35.66111374 35.66111374\n",
            " 36.13659286 35.8988533  36.37433243 38.51399994 38.03852081 39.46496201\n",
            " 39.94044495 39.70270538 38.03852081 38.98947906 38.98947906 40.17818451\n",
            " 40.89140701 41.12914658 40.89140701 40.17818451 40.65366745 40.41592789\n",
            " 40.17818451 40.65366745 38.51399994 39.22722244 38.27626038 39.22722244\n",
            " 39.94044495 38.98947906 40.41592789 40.41592789]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dAAVqwxIBWpa"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ythrMeGBBQkr"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pred Values-- \" ,pred)\n",
        "print(\"\\nOriginal Values-- \",original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX0MmXgdAPL2",
        "outputId": "a9dde6b6-258f-4526-ee1b-974e9107c55a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred Values--  [31.270653 31.221369 31.174221 31.046467 30.960163 30.912539 30.874022\n",
            " 30.86937  30.924835 30.994106 31.092207 31.145483 31.161497 31.166483\n",
            " 31.15354  31.110355 31.047981 30.988    30.918364 30.852772 30.823797\n",
            " 30.804388 30.79612  30.809462 30.812983 30.796919 30.762083 30.653374\n",
            " 30.599167 30.652521 30.704819 30.78178  30.870232 30.953268 31.023857\n",
            " 31.099524 31.156641 31.175734 31.193018 31.1842   31.173073 31.122318\n",
            " 31.075665 30.94317  30.805536 30.70149  30.57862  30.478464 30.389439\n",
            " 30.355446 30.35642  30.319324 30.258823 30.218952 30.231462 30.18761\n",
            " 30.134274 30.112951 30.102488 30.10625  30.08176  30.022991 29.892414\n",
            " 29.785164 29.726152 29.67557  29.578764 29.537477 29.534832 29.54328\n",
            " 29.596338 29.641853 29.699848 29.795872 29.908049 29.987652 30.034588\n",
            " 30.053146 30.131716 30.283388 30.437834 30.5646   30.636236 30.611492\n",
            " 30.534119 30.448988 30.388645 30.34867  30.341156 30.33668  30.314768\n",
            " 30.330744 30.358114 30.39963  30.484064 30.635347 30.77799  30.918982\n",
            " 31.027092 31.108538 31.174063 31.284353 31.43166  31.559998 31.706722\n",
            " 31.828245 31.9399   32.01395  32.149044 32.299267 32.404076 32.50668\n",
            " 32.565804 32.658295 32.777756 32.95354  33.154682 33.299286 33.370926\n",
            " 33.28873  33.206985 33.239403 33.294147 33.314373 33.2406   33.249866\n",
            " 33.357708 33.51973  33.605385 33.6686   33.69084  33.79261  33.961525\n",
            " 34.04208  34.127342 34.205696 34.181824 34.041016 33.78508  33.53834\n",
            " 33.33355  33.243008 33.27035  33.35026  33.439243 33.4556   33.44761\n",
            " 33.501247 33.628296 33.70107  33.685802 33.611725 33.51708  33.471397\n",
            " 33.37966  33.274445 33.26231  33.27995  33.28454  33.29375  33.2754\n",
            " 33.254684 33.268124 33.273766 33.253525 33.22547  33.29222  33.399963\n",
            " 33.523167 33.617214 33.695625 33.84441  33.983387 34.131573 34.277405\n",
            " 34.45661  34.655945 34.84677  34.981285 35.159542 35.370182 35.434963\n",
            " 35.44369  35.382812 35.321163 35.383575 35.75149  36.17859  36.535458\n",
            " 36.80096  37.05016  37.218437 37.340366 37.595505 37.833725 38.012615\n",
            " 38.119595 38.12258  38.165707 38.275013 38.426174 38.51056  38.58103\n",
            " 38.757214 38.827404 38.865646 38.97311  39.151688 39.249466 39.108658\n",
            " 38.937405 38.71378  38.477024 38.38633  38.387703 38.320423 38.307014\n",
            " 38.332447 38.39942  38.480206 38.990734 39.77189  40.52797  41.448082\n",
            " 42.458317 43.188187 43.52039  43.72123  43.809937 43.67219  43.38551\n",
            " 43.076744 43.163906 43.460243 43.734314 43.945927 43.955704 43.74112\n",
            " 43.54696  43.407055 43.32871  43.305363 43.50559  43.75221  43.96472\n",
            " 43.95487  43.926804 43.902153 43.794468 43.50984  43.322044 43.29345\n",
            " 43.38377  43.41072  43.46509  43.48146  43.526894 43.9321   44.53683\n",
            " 44.899376 45.21626  45.35941  45.320442 45.19882  45.071316 44.97816\n",
            " 45.01826  45.001717 44.98561  44.787426 44.655678 44.562523 44.542377\n",
            " 44.635265 44.664062 44.686325 44.79119  44.883995 44.957153 44.76582\n",
            " 44.249912 43.393475 42.691895 41.94595  41.43128  41.29151  41.173954\n",
            " 41.137745 41.165558 41.314056 41.450108 41.4029   41.249947 41.18792\n",
            " 41.10888  41.00465  40.804962 40.466343 39.98189  39.650818 39.256184\n",
            " 38.988213 38.828125 38.691425 38.63623  38.556557 38.52873  38.500496\n",
            " 38.46163  38.454304 38.286087 38.01643  37.93372  38.098694 38.347664\n",
            " 38.538624 38.62172  38.633385 38.64378  38.87295  39.1514   39.622032\n",
            " 40.081104 40.357525 40.584892 40.850506 41.014996 41.252617 41.435986\n",
            " 41.535988 41.554108 41.609463 41.77488  41.894535 41.874493 41.77932\n",
            " 41.591064 41.298836 41.200073 41.276287 41.327805 41.355164 41.420593\n",
            " 41.440895 41.4875   41.604813 41.707855 41.746277 41.792896 41.886387\n",
            " 41.924168 41.682865 41.366528 41.021236 40.75348  40.37884  40.10939\n",
            " 40.25428  40.520042 40.67947  40.89838  41.203995 41.60765  42.011223\n",
            " 42.36438  42.660923 42.91219  43.03323  43.15013  43.29856  43.383442\n",
            " 43.288216 43.06388  42.771675 42.416275 42.144505 42.176052 41.951576\n",
            " 41.813366 41.66672  41.554646 41.453644 41.333405 41.203575 40.829876\n",
            " 40.55442  40.247242 40.0372   39.948566 40.15931  40.273884 40.358818\n",
            " 40.355957 40.41019  40.52067  40.72912  40.77599  40.775085 40.76684\n",
            " 40.61264  40.41883  40.239372 40.091515 39.94824  39.793907 39.64805\n",
            " 39.60489  39.586918 39.615513 39.710575 39.85265  39.97393  40.392742\n",
            " 40.81231  40.994606 40.991703 40.857494 40.666256 40.259235 39.87459\n",
            " 39.605286 39.39158  39.11835  38.877357 38.764717 38.745163 38.45495\n",
            " 38.15628  37.9238   37.780483 37.749954 37.660343 37.69759  37.999023\n",
            " 38.347965 38.706486 39.041546 39.401054 39.52847  39.531387 39.434395\n",
            " 39.288185 39.274258 39.37604  39.590942 39.831604 39.97781  40.00803\n",
            " 40.0044   39.885235 39.764412 39.721764 39.808308 39.93153  40.02117\n",
            " 40.04296  40.061337 40.00578  39.88879  39.80179  39.807064 39.759777\n",
            " 39.678635 39.65309  39.69678  39.758293 39.846603 40.029224 40.11135\n",
            " 40.168766 40.120163 40.048157 39.9843   39.940937 39.836258 39.771614\n",
            " 39.721386 39.667587 39.627796 39.64015  39.749252 39.895245 39.973354\n",
            " 40.10621  40.21834  40.308956 40.441982 40.407234 40.36017  40.24539\n",
            " 40.11749  40.08448  40.105816 40.13765  40.18724  40.208565 40.18458\n",
            " 40.183506 40.22553  40.273895 40.290997 40.34936  40.44618  40.518555\n",
            " 40.658424 40.850105 41.032486 41.156776 41.21199  41.16038  41.076946\n",
            " 41.025192 41.016403 40.951595 40.795464 40.565704 40.373062 40.18803\n",
            " 40.001038 39.86252  39.723274 39.545345 39.341557 39.19611  39.0006\n",
            " 38.796383 38.733246 38.83183  38.914265 38.94727  38.952206 38.96264\n",
            " 39.07255  39.185516 39.28764  39.406082 39.53784  39.586887 39.579277\n",
            " 39.504868 39.416855 39.441376 39.60387  39.869495 40.178894 40.449352\n",
            " 40.620342 40.698257 40.761272 40.80646  40.93061  40.922894 40.824173\n",
            " 40.717377 40.61455  40.52849  40.40613  40.350796 40.344635 40.281086\n",
            " 40.200626 40.154152 40.100945 40.063614 40.03434  40.021774 40.006367\n",
            " 40.005753 39.937057 39.860462 39.791283 39.72803  39.51271  39.259888\n",
            " 38.977158 38.68101  38.309784 37.973988 37.524536 37.1628   36.738876\n",
            " 36.44028  36.314247 36.21959  36.194977 36.093647 36.034912 35.79157\n",
            " 35.498104 35.25221  35.324745 35.70814  36.056637 36.24111  36.41721\n",
            " 36.684765 36.96187  37.25003  37.58104  37.890656 38.13831  38.295124\n",
            " 38.617935 38.9512   39.00671  38.889492 38.742996 38.643833 38.653183\n",
            " 38.65415  38.685947 38.705128 38.74782  38.725754 38.678062 38.606297\n",
            " 38.57553  38.583607 38.594852 38.585377 38.46991  38.440136 38.435776\n",
            " 38.43658  38.359882 38.284946 38.20513  38.203247 38.23595  38.24401\n",
            " 38.245655 38.25166  38.365784 38.50645  38.612232 38.726845 38.879307\n",
            " 38.973625 39.078144 39.128407 39.101215 39.055935 38.996628 38.8869\n",
            " 38.76566  38.631676 38.38922  38.048397 37.761734 37.55059  37.432434\n",
            " 37.359276 37.32655  37.33072  37.31809  37.207092 36.968277 36.760586\n",
            " 36.59714  36.50064  36.400272 36.43247  36.718575 36.952972 37.16245\n",
            " 37.470665 37.67383  37.86061  38.064713 38.168907 38.19745  38.241383\n",
            " 38.22723  38.182934 38.292572 38.629417 39.05004  39.43951  39.72944\n",
            " 39.904285 39.980156 40.002254 39.91462  39.738907 39.603245 39.52393\n",
            " 39.495823 39.527134 39.56915  39.501514 39.35993  38.966915 38.566666\n",
            " 38.207302 37.912262 37.660984 37.399532 37.2026   37.111187 37.16314\n",
            " 37.23199  37.231815 37.23929  37.21934  37.19073  37.150745 37.091633\n",
            " 37.18629  37.422947 37.641594 37.61349  37.46244  37.135815 36.804253\n",
            " 36.118134 35.500656 35.162838 34.90386  34.712234 34.36311  32.57315\n",
            " 30.778788 29.269098 27.70726  26.45241  25.449635 24.66449  24.127108\n",
            " 23.672464 23.821516 23.977488 24.384542 25.135073 25.945942 26.523157\n",
            " 26.75523  27.0066   27.210611 27.74723  28.673586 30.012835 30.993351\n",
            " 31.641052 32.01856  32.221157 32.36816  32.358692 31.98298  31.626617\n",
            " 31.434462 31.201775 30.86603  30.64802  30.540043 30.489048 30.38002\n",
            " 30.355747 30.569498 30.792118 30.903038 31.066685 31.281012 31.55211\n",
            " 31.804745 31.922506 31.989885 32.09695  32.26836  32.438984 32.62858\n",
            " 32.62089  32.599594 32.659332 32.678032 32.567608 32.389866 32.302254\n",
            " 32.364258 32.653473 33.162502 33.925854 34.395927 34.703712 34.791855\n",
            " 34.58045  34.190254 34.002815 33.874336 33.777504 33.794746 33.885674\n",
            " 34.0468   34.045906 33.895813 33.738155 33.577164 33.549614 33.645786\n",
            " 33.871315 34.154327 34.566914 34.84116  34.99206  34.919327 34.68024\n",
            " 34.42624  34.338238 34.25502  34.257973 34.274704 34.524464 34.741875\n",
            " 34.930298 34.92349  34.837166 34.670166 34.573277 34.50154  34.386356\n",
            " 34.377155 34.403397 34.35413  34.239456 34.079872 34.01104  33.92337\n",
            " 33.879425 33.86102  33.767136 33.50602  33.254932 33.06705  33.019646\n",
            " 32.996098 33.034706 33.020546 32.88848  32.75169  32.66192  32.557426\n",
            " 32.3204   32.05479  31.880644 31.729248 31.617716 31.546286 31.527418\n",
            " 31.587845 31.627455 31.616016 31.47495  31.217829 30.7945   30.360746\n",
            " 30.101557 29.947481 29.715935 29.599205 29.464874 29.35956  29.382523\n",
            " 29.442678 29.547726 29.676735 29.917227 30.062576 30.10919  30.07303\n",
            " 29.96313  29.785933 29.623598 29.47987  29.362457 29.252079 29.114948\n",
            " 28.888462 28.669928 28.48478  28.556477 28.737053 29.128546 29.561113\n",
            " 30.080313 30.99925  31.957792 32.650555 33.146286 33.52077  33.744564\n",
            " 33.905426 34.011185 34.117546 34.504864 34.92498  35.457443 36.02349\n",
            " 36.486217 36.58253  36.649925 36.666836 36.82962  37.154125 37.495644\n",
            " 37.77426  37.886887 37.946453 37.97009  37.930763 37.92694  37.61619\n",
            " 37.318874 36.968018 36.77172  36.76486  36.726543 36.839764]\n",
            "\n",
            "Original Values--  [32.84584808 32.84584808 32.18061447 32.59638596 32.59638596 32.4300766\n",
            " 32.59638596 32.84584808 32.76270294 33.01216125 32.67954254 32.59638596\n",
            " 32.67954254 32.59638596 32.4300766  32.34693146 32.4300766  32.26376343\n",
            " 32.26376343 32.34693146 32.34693146 32.34693146 32.4300766  32.34693146\n",
            " 32.18061447 32.0974617  31.68169212 32.0974617  32.67954254 32.34693146\n",
            " 32.59638596 32.67954254 32.67954254 32.67954254 32.84584808 32.76270294\n",
            " 32.67954254 32.76270294 32.59638596 32.67954254 32.4300766  32.51322556\n",
            " 31.84799385 32.01430511 32.01430511 31.7648468  31.84799385 31.68169212\n",
            " 32.01430511 31.93115616 31.59853745 31.51538467 31.59853745 31.93115616\n",
            " 31.3490715  31.43223381 31.59853745 31.51538467 31.59853745 31.3490715\n",
            " 31.18276978 30.76699638 31.01645851 31.09960938 31.01645851 30.68384361\n",
            " 31.09960938 31.01645851 30.93330383 31.26592445 31.09960938 31.26592445\n",
            " 31.59853745 31.59853745 31.43223381 31.43223381 31.43223381 32.01430511\n",
            " 32.26376343 32.26376343 32.26376343 32.0974617  31.68169212 31.59853745\n",
            " 31.68169212 31.7648468  31.7648468  31.93115616 31.7648468  31.68169212\n",
            " 31.93115616 31.93115616 32.01430511 32.34693146 32.67954254 32.59638596\n",
            " 32.76270294 32.67954254 32.76270294 32.76270294 33.26162338 33.42792892\n",
            " 33.8521347  33.93698502 33.8521347  33.93698502 33.76729584 34.44603348\n",
            " 34.44603348 34.27635193 34.44603348 34.27635193 34.78540039 34.95508957\n",
            " 35.29446411 35.63383102 35.29446411 35.12477493 34.44603348 34.95508957\n",
            " 35.46414566 35.46414566 35.12477493 34.61572266 35.46414566 35.80351639\n",
            " 35.97320557 35.46414566 35.63383102 35.46414566 36.31256485 36.48225403\n",
            " 35.97320557 36.31256485 36.48225403 35.80351639 35.29446411 34.78540039\n",
            " 34.78540039 34.78540039 35.29446411 35.63383102 35.63383102 35.63383102\n",
            " 35.29446411 35.29446411 35.80351639 35.97320557 35.63383102 35.29446411\n",
            " 35.12477493 35.12477493 35.46414566 34.95508957 34.78540039 35.46414566\n",
            " 35.29446411 35.12477493 35.12477493 34.95508957 35.12477493 35.29446411\n",
            " 35.12477493 34.95508957 34.95508957 35.63383102 35.63383102 35.80351639\n",
            " 35.63383102 35.80351639 36.31256485 36.1428833  36.48225403 36.65193939\n",
            " 36.9913063  37.16099167 37.33068466 37.16099167 37.83973312 38.0094223\n",
            " 37.33068466 37.33068466 37.16099167 37.33068466 38.17910004 40.04564285\n",
            " 39.70626831 39.53657913 39.53657913 39.87595367 40.04564285 39.87595367\n",
            " 41.06375122 40.89406204 41.06375122 40.72437668 40.55469131 41.06375122\n",
            " 41.40311432 41.74248886 41.23343277 41.5728035  42.25153732 41.5728035\n",
            " 41.74248886 42.25153732 42.59091187 42.42122269 41.06375122 41.06375122\n",
            " 40.72437668 40.72437668 41.40311432 41.40311432 40.72437668 41.23343277\n",
            " 41.23343277 41.40311432 41.5728035  44.28775787 45.81492615 45.64524078\n",
            " 48.02082825 48.6995697  48.19051361 47.17240143 47.68146133 47.85484314\n",
            " 46.81452179 46.12097168 46.29436111 48.375      49.06855392 48.54839706\n",
            " 48.375      47.5080719  46.46775055 46.98791122 46.98791122 47.16129684\n",
            " 47.68146133 48.54839706 48.54839706 48.54839706 47.5080719  47.85484314\n",
            " 47.85484314 47.33468246 46.12097168 46.98791122 47.68146133 47.85484314\n",
            " 47.33468246 47.68146133 47.33468246 47.68146133 50.28226471 50.97581482\n",
            " 49.58871841 50.28226471 49.84880066 48.9818573  48.9818573  48.9818573\n",
            " 49.41532898 49.84880066 49.19859695 49.19859695 48.11492157 48.76512527\n",
            " 48.54839706 49.19859695 49.41532898 48.9818573  48.9818573  49.63206482\n",
            " 49.41532898 49.41532898 47.89818954 46.38105392 43.99698257 45.08064651\n",
            " 43.56351471 44.64718246 45.29737854 44.64718246 44.86391449 45.08064651\n",
            " 45.51411438 45.29737854 44.21371841 43.99698257 44.64718246 44.21371841\n",
            " 44.21371841 43.34678268 42.47984695 41.39617538 42.26311111 41.17944336\n",
            " 41.61290741 41.61290741 41.61290741 41.61290741 41.17944336 41.61290741\n",
            " 41.39617538 41.17944336 41.39617538 40.09577179 40.09577179 40.74597549\n",
            " 42.26311111 42.04637909 41.61290741 41.17944336 41.17944336 41.39617538\n",
            " 42.91331482 42.91331482 44.64718246 44.21371841 43.56351471 44.21371841\n",
            " 44.86391449 44.43044662 45.51411438 45.08064651 44.86391449 44.64718246\n",
            " 45.29737854 45.94758606 45.51411438 44.86391449 44.86391449 44.21371841\n",
            " 43.78024673 44.64718246 45.29737854 44.86391449 44.86391449 45.08064651\n",
            " 44.86391449 45.08064651 45.51411438 45.51411438 45.08064651 45.51411438\n",
            " 45.73085022 45.29737854 43.78024673 43.78024673 43.34678268 43.56351471\n",
            " 42.26311111 42.91331482 45.08064651 44.86391449 44.21371841 45.08064651\n",
            " 45.51411438 46.38105392 46.59778595 46.81452179 46.81452179 47.03125381\n",
            " 46.81452179 47.03125381 47.46472168 47.24798965 46.38105392 45.94758606\n",
            " 45.51411438 44.86391449 45.29737854 46.81452179 44.87858582 45.31856918\n",
            " 44.87858582 44.87858582 44.87858582 44.43859863 44.21860504 42.67865372\n",
            " 43.55862427 42.45865631 42.89864349 43.33863068 44.87858582 43.55862427\n",
            " 43.77861786 43.33863068 43.77861786 44.21860504 44.65859222 43.77861786\n",
            " 43.77861786 43.99861145 43.11863708 42.89864349 42.89864349 42.89864349\n",
            " 42.67865372 42.45865631 42.23866272 42.89864349 42.67865372 42.89864349\n",
            " 43.11863708 43.33863068 43.33863068 45.53855896 45.31856918 44.21860504\n",
            " 43.55862427 43.33863068 43.11863708 41.79868317 42.01867294 42.23866272\n",
            " 42.23866272 41.35869217 41.13870239 41.79868317 41.79868317 39.81874466\n",
            " 40.03873444 40.03873444 40.47872162 40.69871521 40.03873444 41.13870239\n",
            " 42.23866272 42.23866272 42.45865631 42.89864349 43.33863068 42.23866272\n",
            " 42.01867294 41.79868317 41.57868576 42.45865631 42.89864349 43.55862427\n",
            " 43.55862427 43.11863708 42.89864349 42.89864349 42.45865631 42.45865631\n",
            " 42.67865372 43.55862427 43.33863068 43.33863068 42.89864349 43.11863708\n",
            " 42.67865372 42.45865631 42.67865372 43.11863708 42.45865631 42.45865631\n",
            " 42.67865372 43.11863708 42.89864349 43.33863068 43.77861786 43.11863708\n",
            " 43.33863068 42.67865372 42.89864349 42.89864349 42.89864349 42.85353851\n",
            " 43.07908249 42.85353851 42.62799072 42.62799072 43.07908249 43.30462646\n",
            " 43.53017044 43.07908249 43.75571442 43.53017044 43.53017044 43.98125839\n",
            " 43.07908249 43.30462646 42.85353851 42.85353851 43.30462646 43.30462646\n",
            " 43.30462646 43.53017044 43.30462646 43.07908249 43.30462646 43.53017044\n",
            " 43.53017044 43.30462646 43.75571442 43.98125839 43.75571442 44.43235397\n",
            " 44.65789795 44.65789795 44.65789795 44.43235397 43.98125839 43.98125839\n",
            " 44.20680618 44.43235397 43.98125839 43.30462646 42.85353851 43.07908249\n",
            " 42.85353851 42.62799072 42.62799072 42.40244675 41.9513588  41.72581482\n",
            " 41.9513588  41.27472305 41.27472305 41.72581482 42.62799072 41.9513588\n",
            " 41.72581482 41.72581482 41.9513588  42.40244675 42.40244675 42.40244675\n",
            " 42.62799072 42.85353851 42.40244675 42.40244675 41.9513588  41.9513588\n",
            " 42.85353851 43.30462646 43.98125839 44.20680618 44.20680618 43.98125839\n",
            " 43.75571442 43.98125839 43.98125839 44.65789795 43.75571442 43.53017044\n",
            " 43.53017044 43.53017044 43.53017044 43.07908249 43.53017044 43.53017044\n",
            " 43.07908249 43.07908249 43.30462646 43.07908249 43.07908249 43.07908249\n",
            " 43.07908249 43.07908249 43.07908249 42.62799072 42.62799072 42.62799072\n",
            " 42.62799072 41.50026321 41.27472305 41.04917908 40.59808731 39.92145538\n",
            " 39.92145538 38.79372787 39.01927185 38.11709213 38.5681839  39.01927185\n",
            " 38.5681839  38.79372787 38.11709213 38.34263611 36.98936844 36.76382828\n",
            " 36.98936844 39.01927185 39.92145538 39.24481964 38.5681839  39.24481964\n",
            " 39.92145538 40.14699554 40.59808731 41.04917908 41.27472305 41.04917908\n",
            " 41.04917908 42.40244675 42.62799072 41.27472305 40.82363129 41.04917908\n",
            " 41.27472305 41.72581482 41.50026321 41.50026321 41.50026321 41.72581482\n",
            " 41.27472305 41.27472305 41.04917908 41.27472305 41.50026321 41.27472305\n",
            " 41.27472305 40.95262146 41.64283752 41.4127655  41.4127655  40.72255707\n",
            " 40.95262146 40.72255707 41.1826973  41.1826973  40.95262146 40.95262146\n",
            " 40.95262146 41.87290955 41.64283752 41.64283752 41.87290955 42.10297394\n",
            " 41.87290955 42.33304977 41.87290955 41.64283752 41.64283752 41.64283752\n",
            " 41.1826973  41.1826973  40.95262146 40.26241302 39.57219696 39.80226898\n",
            " 39.80226898 40.032341   39.80226898 40.032341   40.032341   39.80226898\n",
            " 39.11205673 38.42184448 38.88198471 38.6519165  38.88198471 38.6519165\n",
            " 39.34212875 40.49248123 40.032341   40.26241302 41.1826973  40.72255707\n",
            " 40.95262146 41.1826973  40.72255707 40.72255707 40.95262146 40.72255707\n",
            " 40.49248123 41.87290955 42.79319382 43.25333405 43.48340607 43.02326202\n",
            " 43.25333405 42.79319382 42.79319382 42.33304977 41.87290955 42.33304977\n",
            " 42.33304977 42.5631218  42.79319382 42.5631218  42.10297394 41.64283752\n",
            " 40.032341   40.26241302 40.032341   40.032341   39.80226898 39.34212875\n",
            " 39.57219696 39.80226898 40.26241302 40.032341   39.57219696 39.80226898\n",
            " 39.57219696 39.57219696 39.57219696 39.34212875 40.49248123 41.1826973\n",
            " 40.95262146 39.34212875 39.11205673 38.19177246 38.42184448 35.89106369\n",
            " 36.12113953 37.50156021 37.35968781 36.88677979 35.46805954 26.4828167\n",
            " 26.95572472 27.66508484 25.06409645 26.4828167  24.82764053 24.59118652\n",
            " 25.06409645 24.35473251 27.90153885 25.77345657 27.42863083 29.55671501\n",
            " 29.55671501 28.37444687 27.42863083 29.0838089  28.61089897 31.9212532\n",
            " 33.57642746 36.17741776 34.04933929 33.81288147 34.04933929 33.81288147\n",
            " 34.04933929 33.57642746 31.44834328 32.39415741 33.33997726 32.15770721\n",
            " 31.44834328 31.9212532  32.15770721 32.15770721 31.68479919 32.15770721\n",
            " 33.57642746 33.10351944 32.39415741 33.33997726 33.57642746 34.28578949\n",
            " 34.04933929 33.57642746 33.57642746 34.04933929 34.5222435  34.75869751\n",
            " 34.99514771 33.81288147 34.28578949 34.75869751 34.5222435  33.57642746\n",
            " 33.57642746 34.04933929 34.99514771 35.94096756 37.35968781 38.54195404\n",
            " 36.88677979 37.1232338  36.41387177 35.23160553 34.5222435  35.94096756\n",
            " 35.94096756 35.70451355 36.17741776 36.41387177 36.65032959 35.46805954\n",
            " 35.23160553 34.99514771 35.23160553 35.70451355 36.41387177 36.88677979\n",
            " 37.1232338  38.06904984 37.35968781 37.1232338  36.17741776 35.46805954\n",
            " 35.94096756 36.65032959 36.17741776 36.65032959 36.41387177 38.06904984\n",
            " 37.35968781 37.59614182 36.41387177 36.41387177 35.94096756 36.88677979\n",
            " 36.41387177 35.94096756 36.88677979 36.65032959 36.17741776 35.70451355\n",
            " 35.46805954 36.17741776 35.70451355 35.94096756 35.94096756 35.23160553\n",
            " 34.28578949 34.5222435  34.75869751 35.23160553 34.99514771 35.23160553\n",
            " 34.75869751 34.04933929 34.28578949 34.5222435  34.04933929 33.10351944\n",
            " 33.33997726 33.33997726 33.10351944 33.10351944 33.33997726 33.33997726\n",
            " 33.81288147 33.33997726 33.10351944 32.39415741 31.68479919 30.73898506\n",
            " 30.73898506 31.68479919 31.44834328 30.43081474 31.38177681 30.66855431\n",
            " 30.66855431 31.38177681 31.38177681 31.38177681 31.61951637 32.57048035\n",
            " 31.61951637 31.38177681 31.14403725 30.90629768 30.66855431 30.66855431\n",
            " 30.66855431 30.66855431 30.43081474 29.95533371 29.47985077 29.47985077\n",
            " 29.47985077 31.14403725 30.90629768 32.33274078 32.33274078 33.04596329\n",
            " 36.37433243 36.37433243 35.42337036 35.66111374 35.66111374 35.66111374\n",
            " 36.13659286 35.8988533  36.37433243 38.51399994 38.03852081 39.46496201\n",
            " 39.94044495 39.70270538 38.03852081 38.98947906 38.98947906 40.17818451\n",
            " 40.89140701 41.12914658 40.89140701 40.17818451 40.65366745 40.41592789\n",
            " 40.17818451 40.65366745 38.51399994 39.22722244 38.27626038 39.22722244\n",
            " 39.94044495 38.98947906 40.41592789 40.41592789]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2HLsUPV3APIo"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(original, color = 'red', label = 'Real  Stock Price')\n",
        "plt.plot(pred, color = 'blue', label = 'Predicted  Stock Price')\n",
        "plt.title(' Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel(' Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1EoNM6VCAPGI",
        "outputId": "8c31acf0-9775-4ac0-840f-f13c51c989db"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TNcOnCVuAPCP"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uY6wsA2wAO-2"
      },
      "execution_count": 87,
      "outputs": []
    }
  ]
}